"use strict";(self.webpackChunkcs_notes=self.webpackChunkcs_notes||[]).push([[1477],{30010:n=>{n.exports=JSON.parse('{"blogPosts":[{"id":"/2023/06/26/scir-test","metadata":{"permalink":"/blog/2023/06/26/scir-test","editUrl":"https://github.com/kcxain/Kcx_Learning/tree/master/blog/2023/06-26-scir-test.md","source":"@site/blog/2023/06-26-scir-test.md","title":"\u54c8\u5de5\u5927 SCIR \u5b9e\u9a8c\u5ba4\u7b14\u8bd5\u5c0f\u8bb0","description":"\u6628\u5929\u53c2\u52a0\u4e86\u54c8\u5de5\u5927 SCIR \u5b9e\u9a8c\u5ba4\u7684 2024 \u7814\u7a76\u751f\u62db\u751f\u7b14\u8bd5\u3002\u8bd5\u9898\u5f88\u57fa\u7840\uff0c\u4f46\u9898\u91cf\u5f88\u5927\uff0c\u4e00\u4e2a\u534a\u5c0f\u65f6\u8981\u5b8c\u6210\u4e00\u9053\u903b\u8f91\u9898\uff0c\u4e00\u9053\u6587\u732e\u7ffb\u8bd1\u9898\uff0c\u4e24\u9053\u6570\u5b66\u9898\uff0c\u4e24\u9053\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u77e5\u8bc6\u7684\u9898\uff0c\u4e24\u9053\u7f16\u7a0b\u9898\u3002\u53cd\u6b63\u6211\u6ca1\u505a\u5b8c\u3002","date":"2023-06-26T00:00:00.000Z","formattedDate":"2023\u5e746\u670826\u65e5","tags":[{"label":"NLP","permalink":"/blog/tags/nlp"},{"label":"\u590d\u76d8","permalink":"/blog/tags/\u590d\u76d8"}],"readingTime":4.385,"hasTruncateMarker":true,"authors":[{"name":"Kcxain","url":"https://github.com/kcxain","email":"kcxain@gmail.com","imageURL":"https://github.com/kcxain.png","key":"kcxain"}],"frontMatter":{"authors":"kcxain","tags":["NLP","\u590d\u76d8"]},"nextItem":{"title":"\u6211\u7528 2 \u4e07\u6761\u804a\u5929\u8bb0\u5f55\uff0c\u521b\u9020\u4e86\u6211\u7684\u6570\u5b57\u751f\u547d","permalink":"/blog/2023/05/24/chatglm"}},"content":"\u6628\u5929\u53c2\u52a0\u4e86\u54c8\u5de5\u5927 SCIR \u5b9e\u9a8c\u5ba4\u7684 2024 \u7814\u7a76\u751f\u62db\u751f\u7b14\u8bd5\u3002\u8bd5\u9898\u5f88\u57fa\u7840\uff0c\u4f46\u9898\u91cf\u5f88\u5927\uff0c\u4e00\u4e2a\u534a\u5c0f\u65f6\u8981\u5b8c\u6210\u4e00\u9053\u903b\u8f91\u9898\uff0c\u4e00\u9053\u6587\u732e\u7ffb\u8bd1\u9898\uff0c\u4e24\u9053\u6570\u5b66\u9898\uff0c\u4e24\u9053\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u77e5\u8bc6\u7684\u9898\uff0c\u4e24\u9053\u7f16\u7a0b\u9898\u3002\u53cd\u6b63\u6211\u6ca1\u505a\u5b8c\u3002\\n\\n\u672c\u6587\u7ed9\u51fa\u4e24\u9053\u6570\u5b66\u9898\u548c\u4e24\u9053\u7f16\u7a0b\u9898\u7684\u9898\u89e3\uff0c\u6743\u5f53\u590d\u4e60\u5de9\u56fa\u57fa\u7840\u3002\\n\\n\x3c!--truncate--\x3e\\n\\n## \u4e00\u3001\u9ad8\u65af\u5206\u5e03\u7684KL\u6563\u5ea6\\n\\n\u8fd9\u9053\u9898\u5b8c\u5168\u7a7a\u7740\u4e86\uff0c\u5fd8\u4e86 KL \u6563\u5ea6\u600e\u4e48\u6c42\u4e86\u3002\u7a76\u5176\u539f\u56e0\u662f\u6ca1\u6709\u6df1\u5165\u7406\u89e3\u4fe1\u606f\u71b5\u3001\u4ea4\u53c9\u71b5\u3001\u76f8\u5bf9\u71b5\u90a3\u4e00\u5957\u539f\u7406[^1]\u3002\\n\\n**\u4fe1\u606f\u71b5\uff1a**\\n$$\\nH_p(X)=-\\\\int p(x)\\\\cdot\\\\log(p(x))\\\\mathrm dx\\n$$\\n$-\\\\log_b(p(x))=\\\\log_b(\\\\frac{1}{p(x)})$\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u4e8b\u4ef6\u7684\u4e0d\u786e\u5b9a\u6027\u7a0b\u5ea6\uff0c\u90a3\u4e48$H_p(X)$\u663e\u7136\u5c31\u662f\u6574\u4e2a\u5206\u5e03\u7684\u671f\u671b\u3002\\n\\n**\u4ea4\u53c9\u71b5\uff1a**\\n$$\\nH_{p_o,p_s}(X)=-\\\\int p_o(x)\\\\cdot\\\\log(p_s(x))\\\\mathrm dx\\n$$\\n\u5176\u4e2d\uff0c$p_s$\u4e3a\u4e3b\u89c2\u8ba4\u4e3a\u7684\u6982\u7387\u5206\u5e03\uff0c\u6216\u8005\u8bf4\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4b\u51fa\u6765\u7684\u6982\u7387\u5206\u5e03\uff0c\u800c$p_o$\u4e3a\u5ba2\u89c2\u7684\u6982\u7387\u5206\u5e03\u3002\u53ef\u4ee5\u7406\u89e3\u4e3a\uff0c\u6211\u4eec\u5e26\u7740\u67d0\u4e2a\u4e3b\u89c2\u8ba4\u77e5\u53bb\u63a5\u89e6\u67d0\u4e2a\u5ba2\u89c2\u968f\u673a\u73b0\u8c61\u7684\u4e0d\u786e\u5b9a\u6027\u7a0b\u5ea6\u3002\\n\\n**\u76f8\u5bf9\u71b5\uff08KL\u6563\u5ea6\uff09\uff1a**\\n$$\\n\\\\begin{aligned}\\nD_{KL}(p_o||p_s) &= H_{p_o,p_s}(X)-H_{p_o}(X) \\\\\\\\\\n&=-\\\\int p_o(x)\\\\cdot\\\\log(\\\\frac{p_s(x)}{p_o(x)})\\\\mathrm dx \\n\\\\end{aligned}\\n$$\\n\u5176\u5b9e\u5c31\u662f\u8861\u91cf\u4ea4\u53c9\u71b5\u4e0e\u4fe1\u606f\u71b5\u7684\u5dee\u503c\u3002\\n\\nKL\u6563\u5ea6\u7684\u82e5\u5e72\u6761\u6027\u8d28\uff1a\\n\\n- KL\u6563\u5ea6\u5927\u4e8e\u7b49\u4e8e 0\uff0c\u7b80\u5355\u8bc1\u660e\uff1a\\n  - \u5bf9$x\\\\in(0,1]$\uff0c\u6709$\\\\text{ln}(x)\\\\le x-1$\uff0c\u4ece\u800c\\n    $$\\n    \\\\begin{aligned}\\n    D_{KL}(p_o||p_s) &=-\\\\int p_o(x)\\\\cdot\\\\text{ln}(\\\\frac{p_s(x)}{p_o(x)})\\\\mathrm dx  \\\\\\\\\\n    &\\\\ge -\\\\int p_o(x)\\\\cdot(\\\\frac{p_s(x)}{p_o(x)}-1)\\\\mathrm dx  \\\\\\\\\\n    &=-\\\\int p_o(x)\\\\cdot(\\\\frac{p_s(x)}{p_o(x)}-1)\\\\mathrm dx  \\\\\\\\\\n    &=-(\\\\int p_s(x)\\\\text{dx} - \\\\int p_o(x)\\\\mathrm dx ) \\\\\\\\\\n    &=0\\n    \\\\end{aligned}\\n    $$\\n- \u53ef\u4ee5\u7406\u89e3\u4e3a\u4e24\u4e2a\u5206\u5e03\u7684\u8ddd\u79bb\uff0c\u4f46\u662f\u5e76\u4e0d\u6ee1\u8db3\u5bf9\u79f0\u6027\u548c\u4e09\u89d2\u4e0d\u7b49\u5f0f\\n\\n\u56de\u5230\u672c\u9898\uff1a\\n$$\\n\\\\begin{aligned}\\n\\\\operatorname{D_{KL}}({\\\\mathcal{N}}(\\\\mu_{1},\\\\sigma_{1}^{2})||{\\\\mathcal{N}}(\\\\mu_{2},\\\\sigma_{2}^{2}))& =\\\\int_{\\\\mathrm x}\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_1}\\\\mathrm e^{-\\\\frac{(x-\\\\mu_1)^2}{2\\\\sigma_1^2}}\\\\log\\\\frac{\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_1}\\\\mathrm e^{-\\\\frac{(x-\\\\mu_1)^2}{2\\\\sigma_1^2}}}{\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_2}\\\\mathrm e^{-\\\\frac{(x-\\\\mu_2)^2}{2\\\\sigma_2^2}}}\\\\mathrm dx  \\\\\\\\\\n&=\\\\int_{x}\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_1}\\\\mathrm{e}^{-\\\\frac{(x-\\\\mu_1)^2}{2\\\\sigma_1^2}}\\\\left[\\\\log\\\\frac{\\\\sigma_2}{\\\\sigma_1}-\\\\frac{(x-\\\\mu_1)^2}{2\\\\sigma_1^2}+\\\\frac{(x-\\\\mu_2)^2}{2\\\\sigma_2^2}\\\\right]\\\\mathrm{dx}\\n\\\\end{aligned}\\n$$\\n\u7b2c\u4e00\u9879\uff1a\\n$$\\n\\\\log\\\\frac{\\\\sigma_2}{\\\\sigma_1}\\\\int_x\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_1}\\\\mathrm{e}^{-\\\\frac{(x-\\\\mu_1)^2}{2\\\\sigma_1^2}}\\\\mathrm{dx}=\\\\log\\\\frac{\\\\sigma_2}{\\\\sigma_1}\\n$$\\n\u7b2c\u4e8c\u9879\u8981\u770b\u51fa\u91cc\u9762\u662f\u65b9\u5dee\uff1a\\n$$\\n-\\\\frac{1}{2\\\\sigma_1^2}\\\\int_x(\\\\mathrm x-\\\\mu_1)^2\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_1}\\\\mathrm e^{-\\\\frac{(\\\\mathrm x-\\\\mu_1)^2}{2\\\\sigma_1^2}}\\\\mathrm dx=-\\\\frac{1}{2\\\\sigma_1^2}\\\\sigma_1^2=-\\\\frac{1}{2}\\n$$\\n\u7b2c\u4e09\u9879\uff0c\u6ce8\u610f$E(x)^2=D(x)+E(x^2)$\\n$$\\n\\\\begin{aligned}\\n\\\\frac{1}{2\\\\sigma_{2}^{2}}\\\\int_{x}(x-\\\\mu_{2})^{2}\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_{1}}\\\\mathrm{e}^{-\\\\frac{(\\\\mathrm{x}-\\\\mu_{1})^{2}}{2\\\\sigma_{1}^{2}}}\\\\mathrm{dx}& =\\\\frac{1}{2\\\\sigma_2^2}\\\\int_{x}(x^2-2\\\\mu_2x+\\\\mu_2^2)\\\\frac{1}{\\\\sqrt{2\\\\pi}\\\\sigma_1}\\\\mathrm{e}^{-\\\\frac{(x-\\\\mu_1)^2}{2\\\\sigma_1^2}}\\\\mathrm{dx}  \\\\\\\\\\n&=\\\\frac{\\\\sigma_1^2+\\\\mu_1^2-2\\\\mu_1\\\\mu_2+\\\\mu_2^2}{2\\\\sigma_2^2}=\\\\frac{\\\\sigma_1^2+(\\\\mu_1-\\\\mu_2)^2}{2\\\\sigma_2^2}\\n\\\\end{aligned}\\n$$\\n\u7efc\u4e0a\uff1a\\n$$\\n\\\\operatorname{D_{KL}}({\\\\mathcal{N}}(\\\\mu_{1},\\\\sigma_{1}^{2})||{\\\\mathcal{N}}(\\\\mu_{2},\\\\sigma_{2}^{2}))=\\\\log\\\\frac{\\\\sigma_2}{\\\\sigma_1}-\\\\frac{1}{2}+\\\\frac{\\\\sigma_1^2+(\\\\mu_1-\\\\mu_2)^2}{2\\\\sigma_2^2}\\n$$\\n\\n## \u4e8c\u3001\u7ec4\u5408\u9898\uff08\u56fe\u8bba\uff09\\n\\n> \u6709 n \u4e2a\u4eba\uff0c\u6bcf\u6b21\u5750\u6210\u4e00\u5708\uff0c\u4e3a\u4e86\u4f7f\u6bcf\u6b21\u6bcf\u4e2a\u4eba\u7684\u90bb\u5c45\u4e0e\u4e4b\u524d\u90fd\u4e0d\u540c\uff0c\u5219\u5750\u6cd5\u6700\u591a\u6709\u51e0\u6b21\uff1f\\n\\n\u5b9e\u9645\u4e0a\u53ef\u4ee5\u62bd\u8c61\u4e3a\uff1a\u5b8c\u5168\u56fe$K_n$\u4e2d\u6700\u591a\u6709\u591a\u5c11\u4e2a\u8fb9\u4e0d\u91cd\u590d\u7684\u54c8\u5bc6\u987f\u5708\u3002\\n\\n\u5f88\u660e\u663e\uff0c\u8981\u5c06\u6bcf\u4e2a\u4eba\u90fd\u8ba4\u8bc6\u4e00\u904d\u4e14\u4e0d\u91cd\u590d\uff0c\u4e0d\u4f1a\u8d85\u8fc7$\\\\lfloor \\\\frac{n-1}{2} \\\\rfloor$\u6b21\uff0c\u4e3b\u8981\u662f\u8003\u8651\u5982\u4f55\u6784\u9020[^2]\uff1a\\n\\n\u5947\u6570\uff1a\\n\\n![](./assets/scir_1.png)\\n\\n\u53ef\u4ee5\u65cb\u8f6c$\\\\frac{n-1}{2}$\u6b21\\n\\n\u5076\u6570\uff1a\\n\\n![](./assets/scir_2.png)\\n\\n\u53ef\u4ee5\u65cb\u8f6c$\\\\frac{n-2}{2}$\u6b21\\n\\n\u6545\uff0c\u7b54\u6848\u4e3a$\\\\lfloor \\\\frac{n-1}{2} \\\\rfloor$\\n\\n## \u4e09\u3001\u7f16\u7a0b\u9898\uff08\u6c42\u7f16\u8f91\u8ddd\u79bb\uff09\\n\\n\u539f\u9898\uff1a[72. \u7f16\u8f91\u8ddd\u79bb - \u529b\u6263](https://leetcode.cn/problems/edit-distance/)\\n\\n\u7ecf\u5178\u7684\u5b57\u7b26\u4e32 dp \u9898\uff1a\\n\\n```cpp\\nint minDistance(string word1, string word2) {\\n    int m = word1.size(), n = word2.size();\\n    vector<vector<int>> dp(m + 1, vector<int>(n + 1));\\n    // dp[i][j] = max(\\n    //\\t\\tdp[i-1][j] + 1, \\t\u5220\u9664\\n    // \\t\\tdp[i][j-1] + 1, \\t\u63d2\u5165\\n    //\\t\\tdp[i-1][j-1] + 1, \\t\u4fee\u6539\\n    //\\t)\\n    for (int i = 0; i <= m; i++) dp[i][0] = i;\\n    for (int j = 0; j <= n; j++) dp[0][j] = j;\\n    for (int i = 1; i <= m; i++) {\\n        for(int j = 1; j <= n; j++) {\\n            dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1);\\n            if (word1[i - 1] == word2[j - 1]) {\\n                dp[i][j] = min(dp[i][j], dp[i-1][j-1]);\\n            }\\n            else {\\n                dp[i][j] = min(dp[i][j], dp[i-1][j-1] + 1);\\n            }\\n        }\\n    }\\n    return dp[m][n];\\n}\\n```\\n\\n## \u56db\u3001\u7f16\u7a0b\u9898\uff08\u6ed1\u52a8\u7a97\u53e3\uff09\\n\\n\u539f\u9898\uff1a[239. \u6ed1\u52a8\u7a97\u53e3\u6700\u5927\u503c - \u529b\u6263](https://leetcode.cn/problems/sliding-window-maximum/)\\n\\n\u4e3b\u8981\u8003\u8651\u5982\u679c i > j\uff0c\u5e76\u4e14 nums[i] > nums[j]\uff0c\u5219 j \u5c31\u53ef\u4ee5\u4e22\u5f03\uff0c\u6545\u7ef4\u62a4\u4e00\u4e2a\u5355\u8c03\u961f\u5217\uff1a\\n\\n```cpp\\nvector<int> maxSlidingWindow(vector<int>& nums, int k) {\\n    int n = nums.size();\\n    deque<int> d;\\n    vector<int> ans;\\n    for(int i = 0; i < n; i++) {\\n        while(!d.empty() && nums[d.back()] <= nums[i]) d.pop_back();\\n        d.push_back(i);\\n        if(i >= k - 1) {\\n            while(!d.empty() && d.front() <= i - k) d.pop_front();\\n            ans.push_back(nums[d.front()]);\\n        }\\n    }\\n    return ans;\\n}\\n```\\n\\n\\n\\n[^1]:[\u4e00\u7bc7\u6587\u7ae0\u8bb2\u6e05\u695a\u4ea4\u53c9\u71b5\u548cKL\u6563\u5ea6 - \u77e5\u4e4e (zhihu.com)](https://zhuanlan.zhihu.com/p/573385147)\\n[^2]:[11\u4e2a\u4eba\u5750\u4e00\u5706\u684c\u513f\uff0c\u6bcf\u6b21\u6bcf\u4eba\u5de6\u53f3\u8fb9\u4e24\u4eba\u90fd\u4e0d\u540c\uff0c\u95ee\u6709\u51e0\u79cd\u5750\u6cd5\uff1f](https://www.zhihu.com/question/47823783)"},{"id":"/2023/05/24/chatglm","metadata":{"permalink":"/blog/2023/05/24/chatglm","editUrl":"https://github.com/kcxain/Kcx_Learning/tree/master/blog/2023/05-24-chatglm.md","source":"@site/blog/2023/05-24-chatglm.md","title":"\u6211\u7528 2 \u4e07\u6761\u804a\u5929\u8bb0\u5f55\uff0c\u521b\u9020\u4e86\u6211\u7684\u6570\u5b57\u751f\u547d","description":"\u672c\u6587\u4ecd\u5728\u6301\u7eed\u66f4\u65b0\u4e2d\uff01","date":"2023-05-24T00:00:00.000Z","formattedDate":"2023\u5e745\u670824\u65e5","tags":[{"label":"NLP","permalink":"/blog/tags/nlp"},{"label":"\u9879\u76ee","permalink":"/blog/tags/\u9879\u76ee"}],"readingTime":4.095,"hasTruncateMarker":true,"authors":[{"name":"Kcxain","url":"https://github.com/kcxain","email":"kcxain@gmail.com","imageURL":"https://github.com/kcxain.png","key":"kcxain"}],"frontMatter":{"authors":"kcxain","tags":["NLP","\u9879\u76ee"]},"prevItem":{"title":"\u54c8\u5de5\u5927 SCIR \u5b9e\u9a8c\u5ba4\u7b14\u8bd5\u5c0f\u8bb0","permalink":"/blog/2023/06/26/scir-test"},"nextItem":{"title":"[\u4ee3\u7801\u89e3\u8bfb] BERT\u53e5\u5b50\u8868\u5f81\u80fd\u529b\u7684\u6539\u8fdb\uff1aCondenser","permalink":"/blog/2023/05/18/condenser"}},"content":"**\u672c\u6587\u4ecd\u5728\u6301\u7eed\u66f4\u65b0\u4e2d\uff01**\\n\\n\u6700\u8fd1\u6709\u4e2a\u5947\u5947\u602a\u602a\u7684\u60f3\u6cd5\uff1a\u5982\u679c\u7528\u6211\u7684\u6240\u6709\u793e\u4ea4\u8f6f\u4ef6\u7684\u804a\u5929\u8bb0\u5f55\u6765\u8bad\u7ec3\u50cf ChatGPT \u8fd9\u6837\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u90a3\u4e48\u5b83\u80fd\u4e0d\u80fd\u5b66\u4f1a\u6211\u7684\u8bf4\u8bdd\u98ce\u683c\uff0c\u751a\u81f3\u62e5\u6709\u6211\u7684\u8bb0\u5fc6\u5462\uff1f\\n\\n\u8bf4\u5e72\u5c31\u5e72\uff0c\u6211\u4ece\u6211\u7684 QQ \u5bfc\u51fa\u6240\u6709\u804a\u5929\u8bb0\u5f55\uff0c\u5e76\u6784\u9020\u51fa\u4e86\u4e24\u4e07\u6761\u5bf9\u8bdd\u6570\u636e\uff0c\u4f7f\u7528 P-Tune v2 \u5fae\u8c03\u6e05\u534e\u5927\u5b66\u5f00\u6e90\u7684 [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) \u6a21\u578b\uff0c\u521b\u9020\u4e86\u6211\u7684\u6570\u5b57\u751f\u547d\uff01\\n\\n\u9879\u76ee\u5df2\u5f00\u6e90\uff1a[kcxain/CloneLLM: Clone Yourself by Fine-tuning a Large Language Model | \u7528\u5927\u8bed\u8a00\u6a21\u578b\u521b\u9020\u4f60\u7684\u6570\u5b57\u751f\u547d\uff01 (github.com)](https://github.com/kcxain/CloneLLM)\\n\\n\x3c!--truncate--\x3e\\n\\n## \u4e00\u3001\u6570\u636e\u96c6\u6784\u9020\\n\\n- \u9884\u5904\u7406\u6570\u636e\uff1a\u4f7f\u7528 QQ \u804a\u5929\u65f6\uff0c\u7528\u6237\u503e\u5411\u4e8e\u5c06\u4e00\u6574\u6bb5\u8bed\u4e49\u5b8c\u6574\u7684\u6d88\u606f\u5206\u6210\u591a\u6761\u53d1\u51fa\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u8be5\u9636\u6bb5\u4f1a\u628a\u540c\u4e00\u7528\u6237\u8fde\u7eed\u53d1\u51fa\u7684\u6240\u6709\u6d88\u606f\u5408\u5e76\u4e3a\u4e00\u6761\u3002\\n- \u6784\u9020\u5bf9\u8bdd\u6570\u636e\u96c6\uff1a\u5bf9\u4e8e\u4f60\u53d1\u51fa\u7684\u6bcf\u6761\u6d88\u606f\uff0c\u5c06\u8fd9\u6761\u6d88\u606f\u8bbe\u7f6e\u4e3a\u591a\u8f6e\u5bf9\u8bdd\u7684\u6700\u540e\u4e00\u6761 response\uff0c\u8be5\u6d88\u606f\u4e4b\u524d\u7684\u6d88\u606f\u4f5c\u4e3a promt\uff0c\u65e0\u8bba\u662f\u79c1\u804a\u8fd8\u662f\u7fa4\u804a\u90fd\u53d6\u524d\u82e5\u5e72\u8f6e\u4f5c\u4e3a\u5bf9\u8bdd\u5386\u53f2\uff08TODO\uff1a\u7fa4\u804a\u662f\u5426\u6709\u66f4\u597d\u7684\u5904\u7406\u65b9\u5f0f\uff1f\uff09\\n\\n\u6700\u540e\u6784\u9020\u7684\u5bf9\u8bdd\u6570\u636e\u96c6\u793a\u4f8b\u5982\u4e0b\uff1a\\n\\n```json\\n{\\n    \\"prompt\\": \\"\u662f\u72b6\u6001\u56fe\u7684\u4e5d\u4e2a\u516c\u5f0f \u5427 \u4e0d\u662f\u4e5d\u4e2a\u72b6\u6001\u56fe\u5427\\",\\n    \\"response\\": \\"\u80fd\u624b\u5199\u5417\\",\\n    \\"history\\": [\\n        [\\"\u95ee\u4e00\u4e0b\u5b50\\", \\"\u54ea\u6765\u7684\u4e5d\u5f20\u72b6\u6001\u8f6c\u79fb\u56fe\u554a \u5c31\u90a3\u4e00\u5f20 \u540e\u9762\u7684\u90fd\u662f\u7ed3\u679c\\"],\\n        [\\"\u54ce\u5440\u7ed9\u6211\u770b\u770b\u561b \u4f60\u4ec0\u4e48\u65f6\u5019\u7a7f\u6b63\u88c5\\", \\"\u4f60\u518d\u628aPPT\u53d1\u7ed9\u6211\\"],\\n        [\\"\u6211\u731c\u7684\u8fd8\u662f\u5f88\u63a5\u8fd1\u6ef4\u561b\\", \\"\u521a\u526a\u5b8c\u5934\\"],\\n        [\\"23 \u6fc0\u60c5\u731c\u4ef7\\", \\"\u732a\u8098\u662f\u53e6\u5916\u73b0\u5207\u7684 9\u5757 \u5269\u4e0b\u768410.5\\"],\\n        [\\"\u5de6\u4e0a\u89d2\u662f\u4ec0\u4e48\\", \\"\u732a\u811a \u731c\u731c\u8fd9\u603b\u5171\u591a\u5c11\u94b1\\"],\\n        [\\"\u4f60\u8bf4\u561e\\", \\"\u6211\u548b\u77e5\u9053\u634f\\"]\\n    ]\\n}\\n{\\n    \\"prompt\\": \\"\u4e0b\u5468\u4e09\u4e4b\u524d\\",\\n    \\"response\\": \\"\u8bba\u6587\u7684\u8fd9\u4e2a\u516c\u5f0f\u9519\u4e86 \u4f60\u53bb\u7fa4\u91cc\u8bf4\u4e00\u4e0b \u8bf4\u8fd9\u4e2a\u8bba\u6587\u4e2d\u8fd9\u4e2a\u516c\u5f0f\u6253\u9519\u4e86 \u5e94\u8be5\u662f\\",\\n    \\"history\\": [\\n        [\\"\u662f\u72b6\u6001\u56fe\u7684\u4e5d\u4e2a\u516c\u5f0f \u5427 \u4e0d\u662f\u4e5d\u4e2a\u72b6\u6001\u56fe\u5427\\", \\"\u80fd\u624b\u5199\u5417\\"],\\n        [\\"\u95ee\u4e00\u4e0b\u5b50\\", \\"\u54ea\u6765\u7684\u4e5d\u5f20\u72b6\u6001\u8f6c\u79fb\u56fe\u554a \u5c31\u90a3\u4e00\u5f20 \u540e\u9762\u7684\u90fd\u662f\u7ed3\u679c\\"],\\n        [\\"\u54ce\u5440\u7ed9\u6211\u770b\u770b\u561b \u4f60\u4ec0\u4e48\u65f6\u5019\u7a7f\u6b63\u88c5\\", \\"\u4f60\u518d\u628aPPT\u53d1\u7ed9\u6211\\"],\\n        [\\"\u6211\u731c\u7684\u8fd8\u662f\u5f88\u63a5\u8fd1\u6ef4\u561b\\", \\"\u521a\u526a\u5b8c\u5934\\"],\\n        [\\"23 \u6fc0\u60c5\u731c\u4ef7\\", \\"\u732a\u8098\u662f\u53e6\u5916\u73b0\u5207\u7684 9\u5757 \u5269\u4e0b\u768410.5\\"],\\n        [\\"\u5de6\u4e0a\u89d2\u662f\u4ec0\u4e48\\", \\"\u732a\u811a \u731c\u731c\u8fd9\u603b\u5171\u591a\u5c11\u94b1\\"]\\n    ]\\n}\\n```\\n\\n## \u4e8c\u3001\u5fae\u8c03\u7b56\u7565\\n\\n### 1. P-tuning v2\\n\\n\u8bba\u6587\u94fe\u63a5\uff1a[P-Tuning v2: Prompt Tuning Can Be Comparable to Finetuning Universally Across Scales and Tasks](https://arxiv.org/abs/2110.07602) \\n\\n![](./assets/P-tuning-v2-1684976826225-2.png)\\n\\n\u7b80\u5355\u6765\u8bf4\uff0c\u5c31\u662f\u5728\u6a21\u578b\u6240\u6709\u5c42\u6dfb\u52a0\u53ef\u8bad\u7ec3\u7684 Prompts \u4f5c\u4e3a Prefix\uff0c\u8bad\u7ec3\u65f6\u51bb\u7ed3\u539f\u59cb\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\uff0c\u53ea\u8bad\u7ec3 Prefix \u90e8\u5206\u3002\\n\\n### 2. LoRA \u5fae\u8c03\\n\\nTODO\\n\\n### 3. \u5168\u53c2\u6570\u5fae\u8c03\\n\\nTODO\\n\\n### 4. \u5fae\u8c03\u53c2\u6570\u96c6\u6210\\n\\n\u89c1 [UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning](https://arxiv.org/abs/2110.07577)\\n\\nTODO\\n\\n## \u4e09\u3001\u7ed3\u679c\u5206\u6790\\n\\n\u76ee\u524d\u7ed3\u679c\u8fd8\u5f88\u5dee\u52b2\uff1a\\n\\n![](./assets/image-20230525005652859.png)\\n\\n- \u56de\u590d\u957f\u5ea6\u7684\u95ee\u9898\u3002\u7531\u4e8e QQ \u5bf9\u8bdd\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u6bcf\u6761\u56de\u590d\u90fd\u975e\u5e38\u77ed\\n- \u56de\u590d\u8d28\u91cf\u95ee\u9898\u3002\u5f88\u591a\u56de\u590d\u7b54\u975e\u6240\u95ee\uff0c\u5e94\u8be5\u662f QQ \u7fa4\u5bf9\u8bdd\u7684\u6570\u636e\u7684\u6c61\u67d3\\n- \u8bb0\u5fc6\u95ee\u9898\u3002\u6a21\u578b\u5e76\u6ca1\u6709\u5f88\u597d\u8bb0\u4f4f\u6211\u7684\u4fe1\u606f\uff0c\u6000\u7591\u662f P-tuning \u5fae\u8c03\u7684\u7f3a\u9677"},{"id":"/2023/05/18/condenser","metadata":{"permalink":"/blog/2023/05/18/condenser","editUrl":"https://github.com/kcxain/Kcx_Learning/tree/master/blog/2023/05-18-condenser.md","source":"@site/blog/2023/05-18-condenser.md","title":"[\u4ee3\u7801\u89e3\u8bfb] BERT\u53e5\u5b50\u8868\u5f81\u80fd\u529b\u7684\u6539\u8fdb\uff1aCondenser","description":"Paper a Pre-training Architecture for Dense Retrieval","date":"2023-05-18T00:00:00.000Z","formattedDate":"2023\u5e745\u670818\u65e5","tags":[{"label":"NLP","permalink":"/blog/tags/nlp"},{"label":"\u4ee3\u7801\u89e3\u8bfb","permalink":"/blog/tags/\u4ee3\u7801\u89e3\u8bfb"}],"readingTime":4.125,"hasTruncateMarker":true,"authors":[{"name":"Kcxain","url":"https://github.com/kcxain","email":"kcxain@gmail.com","imageURL":"https://github.com/kcxain.png","key":"kcxain"}],"frontMatter":{"authors":"kcxain","tags":["NLP","\u4ee3\u7801\u89e3\u8bfb"]},"prevItem":{"title":"\u6211\u7528 2 \u4e07\u6761\u804a\u5929\u8bb0\u5f55\uff0c\u521b\u9020\u4e86\u6211\u7684\u6570\u5b57\u751f\u547d","permalink":"/blog/2023/05/24/chatglm"},"nextItem":{"title":"DSTC11-Track5 \u7ade\u8d5b\u603b\u7ed3","permalink":"/blog/2023/04/10/dstc"}},"content":"> Paper: [Condenser: a Pre-training Architecture for Dense Retrieval](https://arxiv.org/abs/2104.08253)\\n>\\n> Code: https://github.com/luyug/Condenser\\n>\\n> Publication: EMNLP 2021\\n\\n\u6700\u8fd1\u5728\u5fd9\u7684\u9879\u76ee\u9700\u8981\u4e00\u4e2a\u597d\u7684\u65b9\u6cd5\u6765\u8868\u5f81\u53e5\u5b50\uff0c\u4e8e\u662f\u5c31\u8bfb\u5230\u4e86\u8fd9\u7bc7\u8bba\u6587\u3002\u8fd9\u7bc7\u8bba\u6587\u7684 idea \u548c\u4ee3\u7801\u90fd\u4e0d\u590d\u6742\uff0c\u57fa\u672c\u4e0a\u5c31\u662f\u5bf9 Bert \u7684\u4e00\u4e2a\u7b80\u5355\u6539\u9020\u3002\u6211\u5199\u672c\u6587\u7684\u76ee\u7684\u662f\u8bb0\u5f55\u5b66\u4e60\u4e00\u4e0b\u5b83\u6539\u9020 bert \u7684\u4ee3\u7801\u6280\u5de7\u3002\\n\\n\x3c!--truncate--\x3e\\n\\n## \u4e00\u3001\u6a21\u578b\u52a8\u673a\\n\\nCondenser \u7684\u52a8\u673a\u6765\u6e90\u4e8e\u4e00\u4e2a\u5df2\u53d1\u73b0\u7684\u73b0\u8c61\uff1a\u4e00\u4e2a\u9884\u8bad\u7ec3\u597d\u7684 Bert \u4e2d\uff0c\u4e2d\u95f4\u5c42\u7684 CLS \u4e0e\u53e5\u5b50\u4e2d\u7684\u5176\u4ed6 token \u7684 attention \u7cfb\u6570\u5f88\u4f4e\uff0c\u76f4\u5230\u6700\u540e\u4e00\u5c42 CLS \u624d\u4e0e\u6240\u6709\u7684 token \u6709\u6bd4\u8f83\u5927\u7684 attention\u7cfb\u6570\u3002\u6240\u4ee5\uff0c\u662f\u5426\u53ef\u4ee5\u8ba9\u6700\u540e\u4e00\u5c42\u7684 CLS \u5411\u91cf\u4e0e\u4e2d\u95f4\u5c42\u7684\u5176\u5b83 token \u7684\u5411\u91cf\u505a self-attention \u5b66\u4e60\u5462\uff1f\\n\\n## \u4e8c\u3001\u6a21\u578b\u7ed3\u6784\\n\\n\u57fa\u4e8e\u8fd9\u6837\u7684\u52a8\u673a\uff0c\u6a21\u578b\u5982\u4e0b\uff1a\\n\\n![](./assets/image-20230518103007659.png)\\n\\n\u5c06 12 \u5c42 BertLayer \u5206\u4e3a Late \u548c Early\uff0c\u5404 6 \u5c42\u3002\u7528\u7b2c 12 \u5c42\u7684 CLS \u4f4d\u7f6e\u5411\u91cf\u4e0e\u7b2c 6 \u5c42\u9664 CLS \u4f4d\u7f6e\u7684\u5176\u4ed6\u9690\u85cf\u5411\u91cf\u62fc\u63a5\u6210\u539f\u957f\u5ea6\u7684\u8f93\u51fa\u5411\u91cf\uff0c\u6700\u540e\u63a5\u4e00\u4e2a 2 \u5c42 BertLayer \u8bad\u7ec3\u3002\\n\\n12 \u5c42 BertLayer \u7684\u6743\u91cd\u5c31\u4ece\u5df2\u7ecf\u9884\u8bad\u7ec3\u597d\u7684 Bert \u4e2d\u52a0\u8f7d\u3002\u800c\u7531\u4e8e\u6700\u4e0a\u9762\u7684\u4e24\u5c42 BertLayer \u662f\u81ea\u5df1\u6dfb\u52a0\u7684\uff0c\u5176\u6743\u91cd\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\u3002\u4e3a\u4e86\u9632\u6b62\u8fd9\u4e24\u5c42\u7684\u968f\u673a\u6743\u91cd\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u5bf9\u6574\u4e2a\u6a21\u578b\u7684\u6743\u91cd\u6709\u7834\u574f\u3002\u6240\u4ee5\u5728\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\u65f6\uff0c\u628a\u6700\u539f\u59cb\u7684 Bert \u7684 MLM \u635f\u5931\u4e5f\u8981\u52a0\u4e0a\u3002\\n\\n## \u4e09\u3001\u4ee3\u7801\u89e3\u8bfb\\n\\n\u4e0b\u9762\u4ecb\u7ecd\u6211\u5b66\u5230\u7684\u4e00\u4e9b\u4ee3\u7801\u6280\u5de7\u3002\\n\\n### 1. \u5982\u4f55\u521d\u59cb\u5316\u7684\u81ea\u5b9a\u4e49 BertLayer\uff1f\\n\\n\u9996\u5148\uff0c\u9700\u8981\u5b9a\u4e49\u81ea\u5df1\u8bbe\u7f6e\u7684 BertLayer\uff1a\\n\\n```python\\nself.c_head = nn.ModuleList(\\n    # \u8bba\u6587\u4e2dmodel_args.n_head_layers=2\\n    [BertLayer(bert.config) for _ in range(model_args.n_head_layers)]\\n)\\n```\\n\\n\u5bf9\u4e8e\u8fd9\u4e2a ModuleList \u4e2d\u7684\u6bcf\u4e2a Module\uff0c\u53ef\u4ee5\u4f7f\u7528 apply \u65b9\u6cd5\uff0c\u8fdb\u884c\u6743\u91cd\u521d\u59cb\u5316\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u9700\u8981\u4e00\u4e2a\u63a5\u6536 Module \u4e3a\u53c2\u6570\u7684\u51fd\u6570\\n\\nhuggingface \u7684\u6bcf\u4e2a`PreTrainedModel`\u90fd\u6709`init_weights`\u65b9\u6cd5\uff0c\u8fd9\u662f\u8bf4\u660e\u6587\u6863\uff1a\\n\\n:::info `init_weights`\\n\\nIf needed prunes and maybe initializes weights. If using a custom `PreTrainedModel`, you need to implement any initialization logic in `_init_weights`.\\n\\n:::\\n\\n\u6240\u4ee5\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528 BertModel \u7684\u521d\u59cb\u5316\u6743\u91cd\u65b9\u6cd5\u6765\u521d\u59cb\u5316\u81ea\u5b9a\u4e49\u7684 BertLayer\uff1a\\n\\n```python\\nself.lm = BertModel\\nself.c_head.apply(self.lm._init_weights)\\n```\\n\\n\u6211\u4eec\u4e5f\u53ef\u4ee5\u770b\u770b BertModel \u4e2d\u7684\u8fd9\u4e2a\u65b9\u6cd5\uff1a\\n\\n```python\\ndef _init_weights(self, module):\\n    \\"\\"\\"Initialize the weights\\"\\"\\"\\n    if isinstance(module, nn.Linear):\\n        # Slightly different from the TF version which uses truncated_normal for initialization\\n        # cf https://github.com/pytorch/pytorch/pull/5617\\n        module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\\n        if module.bias is not None:\\n            module.bias.data.zero_()\\n    elif isinstance(module, nn.Embedding):\\n        module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\\n        if module.padding_idx is not None:\\n            module.weight.data[module.padding_idx].zero_()\\n    elif isinstance(module, nn.LayerNorm):\\n        module.bias.data.zero_()\\n        module.weight.data.fill_(1.0)\\n```\\n\\nBert \u4e2d\u7684 initializer_range=0.02\uff0c\u4e5f\u5c31\u662f\u7528 mean=0\uff0cstd=0.02 \u6765\u968f\u673a\u521d\u59cb\u5316\u53c2\u6570\u3002\\n\\n### 2.\u5982\u4f55\u5f97\u5230\u7279\u5b9a\u9690\u85cf\u5c42\u7684\u8f93\u51fa\uff1f\\n\\n`MaskedLMOutput`\u6709\u8fd9\u6837\u51e0\u4e2a\u503c\uff1a\\n\\n- last_hidden_state: (batch_size, sequence_length, hidden_size)\uff0c\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u7684\u9690\u85cf\u72b6\u6001\\n- pooler_output: (batch_size, hidden_size)\uff0c\u5e8f\u5217\u7b2c\u4e00\u4e2a token \u6700\u540e\u4e00\u5c42\u7684\u9690\u85cf\u72b6\u6001\\n- hidden_states: \u9700\u8981\u6307\u5b9a`config.output_hidden_states=True`\uff0c\u8fd9\u662f\u4e00\u4e2a\u5143\u7ec4\uff0c\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e3a embedding\uff0c\u5176\u4f59\u5143\u7d20\u662f\u5404\u5c42\u7684\u8f93\u51fa\uff0c\u6bcf\u4e2a\u5143\u7d20\u7684\u5f62\u72b6\u4e3a (batch_size, sequence_length, hidden_size)\\n- attentions: \u9700\u8981 `config.output_attentions=True`\uff0c\u8fd9\u662f\u4e00\u4e2a\u5143\u7ec4\uff0c\u5143\u7d20\u662f\u6bcf\u4e00\u5c42\u7684\u6ce8\u610f\u529b\u6743\u91cd\\n\\n\u6240\u4ee5\uff0c\u8981\u5f97\u5230 CLS \u6700\u540e\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u53ef\u4ee5\u8fd9\u6837\uff1a\\n\\n```python\\ncls_hiddens = lm_out.hidden_states[-1][:, :1]\\n```\\n\\n\u5f97\u5230\u5176\u5b83\u4f4d\u7f6e\u7b2c 6 \u5c42\u7684\u8f93\u51fa\uff0c\u53ef\u4ee5\u8fd9\u6837\uff1a\\n\\n```python\\nskip_hiddens = lm_out.hidden_states[6][:, 1:]\\n```\\n\\n## \u4e09\u3001TODO\\n\\n\u6682\u4e14\u5148\u5199\u8fd9\u4e9b\u5185\u5bb9\uff0c\u4ee5\u540e\u6709\u65f6\u95f4\u5c31\u4ee5\u8fd9\u4e2a\u6a21\u578b\u4e3a\u4f8b\u8bb2\u8bb2\u5982\u4f55\u628a\u81ea\u5df1\u7684\u6a21\u578b\u52a0\u5165 transformers \u5e93\u4e2d"},{"id":"/2023/04/10/dstc","metadata":{"permalink":"/blog/2023/04/10/dstc","editUrl":"https://github.com/kcxain/Kcx_Learning/tree/master/blog/2023/04-10-dstc.md","source":"@site/blog/2023/04-10-dstc.md","title":"DSTC11-Track5 \u7ade\u8d5b\u603b\u7ed3","description":"\u6628\u5929\uff0cDSTC \u7ade\u8d5b\u7684\u7ed3\u679c\u51fa\u6765\u4e86\u3002\u6392\u540d\u51fa\u4e4e\u610f\u6599\uff1a\u4e00\u5171 14 \u4e2a\u961f\u63d0\u4ea4\uff0c\u6211\u961f\u6309\u7167\u5ba2\u89c2\u6307\u6807\u6392\u5728\u7b2c 3 \u540d\uff01\u6392\u540d\u5982\u56fe\uff08\u6211\u961f\u4e3a\u7b2c 7 \u961f\uff09","date":"2023-04-10T00:00:00.000Z","formattedDate":"2023\u5e744\u670810\u65e5","tags":[{"label":"NLP","permalink":"/blog/tags/nlp"},{"label":"\u590d\u76d8","permalink":"/blog/tags/\u590d\u76d8"}],"readingTime":6.945,"hasTruncateMarker":true,"authors":[{"name":"Kcxain","url":"https://github.com/kcxain","email":"kcxain@gmail.com","imageURL":"https://github.com/kcxain.png","key":"kcxain"}],"frontMatter":{"title":"DSTC11-Track5 \u7ade\u8d5b\u603b\u7ed3","authors":"kcxain","tags":["NLP","\u590d\u76d8"]},"prevItem":{"title":"[\u4ee3\u7801\u89e3\u8bfb] BERT\u53e5\u5b50\u8868\u5f81\u80fd\u529b\u7684\u6539\u8fdb\uff1aCondenser","permalink":"/blog/2023/05/18/condenser"},"nextItem":{"title":"BERT \u5bb6\u65cf\u5927\u5168\u89e3\u2014\u2014RoBERTa, DeBERTa","permalink":"/blog/2022/11/12/bert-family"}},"content":"\u6628\u5929\uff0cDSTC \u7ade\u8d5b\u7684\u7ed3\u679c\u51fa\u6765\u4e86\u3002\u6392\u540d\u51fa\u4e4e\u610f\u6599\uff1a\u4e00\u5171 14 \u4e2a\u961f\u63d0\u4ea4\uff0c\u6211\u961f\u6309\u7167\u5ba2\u89c2\u6307\u6807\u6392\u5728\u7b2c 3 \u540d\uff01\u6392\u540d\u5982\u56fe\uff08\u6211\u961f\u4e3a\u7b2c 7 \u961f\uff09\\n\\n\x3c!--truncate--\x3e\\n\\n![](./assets/image-20230410172909573.png)\\n\\n\u53ef\u4ee5\u770b\u5230\uff0c\u867d\u7136\u548c\u524d\u4e24\u961f\u5dee\u8ddd\u8f83\u5927\uff0c\u4f46\u7b2c 3 \u5df2\u7ecf\u662f\u4e00\u4e2a\u76f8\u5f53\u4e0d\u9519\u7684\u540d\u6b21\u4e86\uff08\u5c24\u5176\u662f\u6211\u8d1f\u8d23\u7684 Turn Detection \u90e8\u5206\u62ff\u5230\u4e86\u7b2c 1 \u540d\uff01)\\n\\n## \u8d5b\u9898\u4ecb\u7ecd\\n\\nDSTC11-Track5 \u7684\u4e3b\u9898\u662f Task-oriented Conversational Modeling with Subjective Knowledge\uff0c\u5c31\u662f\u5229\u7528\u4e3b\u89c2\u77e5\u8bc6\u5bf9\u4efb\u52a1\u578b\u5bf9\u8bdd\u8fdb\u884c\u5efa\u6a21\u3002\\n\\n \u6574\u4e2a\u4efb\u52a1\u88ab\u5212\u5206\u4e3a\u4e86 three stage\uff1a\\n\\n- Turn Detection\u3002\u5224\u65ad\u5f53\u524d\u7684\u5bf9\u8bdd\u662f\u5426\u9700\u8981\u5916\u90e8\u77e5\u8bc6\\n- Knowledge Selection\u3002\u5728\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u6587\u6863\u4e2d\u9009\u51fa\u76f8\u5173\u7684\u77e5\u8bc6\u5019\u9009\\n- Response Generation\u3002\u6839\u636e\u7b2c\u4e8c\u6b65\u7684\u77e5\u8bc6\u5019\u9009\u751f\u6210\u56de\u590d\\n\\n\u5982\u56fe\u6240\u793a[^1]\uff1a\\n\\n![](./assets/image-20230416233037362.png)\\n\\n\u7ed9\u5b9a\u7684\u6570\u636e\u96c6\u5305\u62ec\u591a\u8f6e\u5bf9\u8bdd\uff0c\u4ee5\u53ca\u6bcf\u8f6e\u5bf9\u8bdd\u7684\u6807\u7b7e\uff08\u662f\u5426\u9700\u8981\u5916\u90e8\u77e5\u8bc6\uff0c\u9700\u8981\u7684\u77e5\u8bc6\u5019\u9009)\u3002\u5176\u4e2d\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u5305\u542b\u4e24\u4e2a\u57df\uff0c\u6bcf\u4e2a\u57df\u53c8\u6709\u82e5\u5e72\u5b9e\u4f53\u3002\u786e\u5b9a\u5f53\u524d\u5bf9\u8bdd\u76f8\u5173\u7684\u5b9e\u4f53\u662f\u5f88\u91cd\u8981\u7684\u3002\\n\\n\u7b2c\u4e00\u6b65\u3001\u7b2c\u4e8c\u6b65\u7684\u8bc4\u4ef7\u6307\u6807\u5747\u4e3a Precision/Recall/F-measure\uff0c\u751f\u6210\u56de\u590d\u7684\u6307\u6807\u4e3a BLEU\uff0cROUGE\uff0cMETOR\u3002\\n\\n## Baseline \u505a\u6cd5\\n\\nTurn Detection \u9636\u6bb5\uff1a\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u4f7f\u7528 Roberta \u6a21\u578b\uff0c\u5c06\u5bf9\u8bdd\u4e0a\u6587\u548c\u67e5\u8be2\u4f5c\u4e3a\u8f93\u5165\uff0c\u5c06 Roberta \u7684 CLS \u6807\u7b7e\u52a0\u5168\u8fde\u63a5\u5c42\u540e\u4f5c\u4e3a\u8f93\u51fa\uff0c\u635f\u5931\u51fd\u6570\u7528\u4ea4\u53c9\u71b5\u3002\\n\\nKnowledge Sealetion \u9636\u6bb5\uff1a\u8fd8\u662f\u5c06\u95ee\u9898\u770b\u4f5c\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u5bf9\u6bcf\u4e00\u6761\u77e5\u8bc6\u9010\u4e00\u5224\u65ad\u662f\u5426\u52a0\u5165\u5019\u9009\uff0c\u4e0e Turn Detection \u76f8\u540c\u7684\u505a\u6cd5\uff0c\u53ea\u4e0d\u8fc7\u8f93\u5165\u589e\u52a0\u4e86\u9700\u8981\u5224\u65ad\u7684\u77e5\u8bc6\u6761\u76ee\u3002\u8fd9\u79cd\u505a\u6cd5\u9700\u8981\u5bf9\u6bcf\u4e00\u6761\u77e5\u8bc6\u9010\u4e00\u5224\u65ad\uff0c\u65f6\u95f4\u6d88\u8017\u96be\u4ee5\u627f\u53d7\uff0c\u56e0\u6b64\uff0cBaseline \u63d0\u51fa\u7684\u6539\u8fdb\u662f\uff0c\u5148\u5728\u5bf9\u8bdd\u4e0a\u6587\u4e2d\u4f7f\u7528\u673a\u68b0\u7684\u6a21\u7cca\u5339\u914d\u6765\u786e\u5b9a\u5f53\u524d\u5bf9\u8bdd\u6240\u5173\u8054\u7684\u57df\uff0c\u7136\u540e\u5bf9\u8fd9\u4e2a\u57df\u4e2d\u7684\u77e5\u8bc6\u518d\u9010\u4e00\u5224\u65ad\u3002\\n\\nResponse Generation \u9636\u6bb5\uff1a\u4f7f\u7528 Bard \u6a21\u578b\uff0c\u5c06\u5bf9\u8bdd\u4e0a\u6587\uff0c\u67e5\u8be2\uff0c\u77e5\u8bc6\u5019\u9009\u8f93\u5165\u5f97\u5230\u56de\u590d\u3002\\n\\n## \u7ade\u8d5b\u8fc7\u7a0b\\n\\n\u6211\u4eec\u662f\u4ece 2 \u6708 20 \u65e5\u5f00\u59cb\u51c6\u5907\u7684\uff0c\u5230 4 \u6708 1 \u65e5\u63d0\u4ea4\u7ed3\u679c\u5dee\u4e0d\u591a\u6709\u4e00\u4e2a\u534a\u6708\u7684\u65f6\u95f4\u3002\u524d\u671f\u7684\u5de5\u4f5c\u4e3b\u8981\u5c31\u662f\u8bfb Baseline\uff0c\u8bfb\u9886\u57df\u5185\u8bba\u6587\u3002\u5728\u8fd9\u671f\u95f4\uff0c\u5bf9\u6211\u63d0\u5347\u5f88\u5927\u7684\u662f\u8bfb Baseline \u4ee3\u7801\u3002DSTC \u7ec4\u7ec7\u65b9\u63d0\u4f9b\u7684\u4ee3\u7801\u67b6\u6784\u7b80\u76f4\u592a\u597d\u4e86\uff0c\u6a21\u5757\u4e4b\u95f4\u8026\u5408\u5ea6\u4f4e\uff0c\u6574\u4efd\u4ee3\u7801\u7684\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u6269\u5c55\u6027\u975e\u5e38\u9ad8\uff0c\u8bfb\u8d77\u6765\u7b80\u76f4\u5c31\u662f\u4e00\u79cd\u4eab\u53d7\uff01\uff08\u6211\u6628\u5929\u624d\u5199\u5b8c\u7684\u8bba\u6587\u5b9e\u9a8c\u5c31\u662f\u5728\u8fd9\u4e2a\u67b6\u6784\u4e0a\u4fee\u6539\u7684\uff09\u3002\u800c\u8bfb\u9886\u57df\u5185\u8bba\u6587\u5374\u8db3\u8db3\u4f7f\u6211\u714e\u71ac\u4e86\u4e00\u4e2a\u6708\uff0c\u5c24\u5176\u662f\u5f80\u5c4a DSTC \u7ade\u8d5b\u6295\u7a3f\u7684 Workshop \u8bba\u6587\uff0c\u63d0\u51fa\u7684\u5f88\u591a idea \u5f88\u597d\uff0c\u4f46\u662f\u5f00\u6e90\u7684\u4ee3\u7801\u5374\u6ca1\u4e00\u4e2a\u80fd\u8dd1\u3002\u6211\u82b1\u4e86\u4e00\u4e2a\u6708\u65f6\u95f4\u5929\u5929\u6574\u7406\u3001\u8c03\u8bd5\u8fd9\u4e9b\u4ee3\u7801\uff0c\u8dd1\u901a\u540e\u7684\u6548\u679c\u5374\u975e\u5e38\u5dee\u52b2\uff0c\u6211\u81f3\u4eca\u4e0d\u6e05\u695a\u662f\u8bba\u6587\u6570\u636e\u7684\u95ee\u9898\u8fd8\u662f\u6211\u5199\u7684\u4ee3\u7801\u7684\u95ee\u9898\u3002\u603b\u4e4b\uff0c\u8fd9\u4e00\u4e2a\u6708\u6b9a\u7cbe\u7aed\u8651\uff0c\u5374\u51e0\u4e4e\u6ca1\u6709\u4efb\u4f55\u4ea7\u51fa\u3002\\n\\n\u4ece 3 \u6708 20 \u65e5\u5f00\u59cb\uff0c\u6211\u4fbf\u653e\u5f03\u4e86\u4f7f\u7528\u4ed6\u4eba\u8bba\u6587\u7684 idea\uff0c\u800c\u662f\u5728 Baseline \u4e0a\u4fee\u6539\u3002\u4e3b\u8981\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u63d0\u9ad8\u6a21\u578b\u80fd\u529b\uff1a\\n\\n- **\u6570\u636e**\u65b9\u9762\u3002\u5bf9\u6570\u636e\u96c6\u91c7\u7528\u56de\u8bd1\u7684\u65b9\u5f0f\u8fdb\u884c\u6570\u636e\u589e\u5f3a\\n- **\u6a21\u578b**\u65b9\u9762\u3002\u5148\u4f7f\u7528\u6570\u636e\u96c6\u5bf9\u6a21\u578b\u8fdb\u884c\u9884\u8bad\u7ec3\u540e\u518d\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u5fae\u8c03\uff1b\u6362\u7528\u4e0d\u540c\u53c2\u6570\u5927\u5c0f\u7684\u6a21\u578b\uff0c\u4fee\u6539\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u67e5\u770b\u6536\u655b\u540e\u7684\u7ed3\u679c\\n- **\u6a21\u578b\u878d\u5408**\u3002\u6700\u540e\u901a\u8fc7\u6a21\u578b\u878d\u5408\u63d0\u9ad8\u6a21\u578b\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\uff08\u8fd9\u5927\u6982\u662f Task 1 \u80fd\u62ff\u5230\u7b2c 1 \u540d\u7684\u4e3b\u8981\u539f\u56e0\uff09\\n\\n\u8fd9\u671f\u95f4\uff0c\u6211\u8fd8\u7528\u4e86\u4e00\u4e2a\u665a\u4e0a\uff0c\u901a\u8fc7\u628a Baseline \u7684 Task 2 \u635f\u5931\u51fd\u6570\u6362\u4e3a infoNCE \u7684\u65b9\u5f0f\uff0c\u5c06\u4efb\u52a1\u4ece\u4e8c\u5206\u7c7b\u95ee\u9898\u8f6c\u6362\u4e3a\u6392\u5e8f\u95ee\u9898\u3002\u7136\u800c\u6700\u540e\u7684\u6548\u679c\u5374\u662f\u60e8\u4e0d\u5fcd\u7779\u3002\u4e5f\u662f\u4ece\u8fd9\u4ee5\u540e\uff0c\u6211\u5b8c\u5168\u653e\u5f03\u4e86\u5728 Baseline \u7684\u6a21\u578b\u7ed3\u6784\u4e0a\u52a8\u5200\u3002\\n\\n\u73b0\u5728\u60f3\u60f3\uff0c\u5176\u5b9e\u8fd9\u6b21\u6bd4\u8d5b\u524d\u671f\u7684\u8bfb\u8bba\u6587\u3001\u590d\u73b0\u8bba\u6587\u5de5\u4f5c\u4e5f\u5e76\u4e0d\u662f\u6beb\u65e0\u610f\u4e49\u7684\u3002\u6211\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u5230\u4e86\u6570\u636e\u589e\u5f3a\u7684\u6280\u5de7\uff0c\u52a0\u6df1\u4e86\u76f8\u5173\u9886\u57df\u4efb\u52a1\u7684\u7406\u89e3\uff0c\u5bf9\u540e\u9762\u7684\u8c03\u53c2\u5de5\u4f5c\u6709\u5f88\u5927\u7684\u79ef\u6781\u4f5c\u7528\u3002\u5f53\u7136\uff0c\u8c03\u53c2\u5de5\u4f5c\u4e5f\u6709\u5f88\u591a\u53ef\u4ee5\u6539\u8fdb\u7684\u5730\u65b9\uff1a\\n\\n- \u5e94\u9996\u5148\u5206\u6790\u3001\u63d0\u5347\u539f\u59cb\u6570\u636e\u7684\u8d28\u91cf\u3002\u4f8b\u5982\uff1a\u6839\u636e\u6807\u7b7e\u3001\u6570\u636e\u957f\u5ea6\u53bb\u9664\u4f4e\u8d28\u91cf\u6570\u636e\\n- \u5e94\u641c\u96c6\u4e00\u5207\u53ef\u4ee5\u641c\u96c6\u5230\u7684\u76f8\u5173\u9886\u57df\u6570\u636e\u8fdb\u884c\u6a21\u578b\u9884\u8bad\u7ec3\u3002\u4f8b\u5982\uff0cWizard of Wikipedia \u6570\u636e\u96c6\u4e5f\u662f\u591a\u8f6e\u5bf9\u8bdd\u4e14\u6807\u6ce8\u5916\u90e8\u77e5\u8bc6\u70b9\u7684\u6570\u636e\u96c6\uff0c\u5b8c\u5168\u53ef\u4ee5\u62ff\u6765\u505a\u9884\u8bad\u7ec3\u751a\u81f3\u5fae\u8c03\\n\\n\u6211\u5bf9\u8fd9\u573a\u7ade\u8d5b\u7684\u7ed3\u679c\u672c\u6765\u662f\u5f88\u4e0d\u770b\u597d\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u6700\u540e\u505a\u7684\u57fa\u672c\u90fd\u662f\u8c03\u53c2\u3001\u6362\u6a21\u578b\u8fd9\u7c7b\u5de5\u4f5c\uff0c\u6392\u540d\u600e\u4e48\u4f1a\u9ad8\u5462\uff1f\u7136\u800c\u4e8b\u5b9e\u8bc1\u660e\uff0c\u8fd9\u6837\u505a\u5c31\u662f\u80fd\u62ff\u5230\u4e0d\u9519\u7684\u6392\u540d\u3002\u6211\u4e2a\u4eba\u8ba4\u4e3a\u539f\u56e0\u662f\u5728 nlp \u5806\u5927\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u4ee3\uff0c\u6570\u636e\u5927\u5c0f\u3001\u6570\u636e\u8d28\u91cf\u5bf9\u6a21\u578b\u6548\u679c\u7684\u5f71\u54cd\u8fdc\u8fdc\u8d85\u8fc7\u6a21\u578b\u7ed3\u6784\u672c\u8eab\u3002\\n\\n\u603b\u4e4b\uff0c\u4ee5\u540e\u5728\u53c2\u52a0\u7ade\u8d5b\u65f6\uff0c\u5148\u4e0d\u8981\u53bb\u60f3\u90a3\u4e9b\u5929\u9a6c\u884c\u7a7a\u7684 idea\uff0c\u4e0d\u59a8\u53bb\u505a\u505a\u6570\u636e\u589e\u5f3a\uff0c\u8c03\u8c03\u53c2\u5427\uff0c\u7ed3\u679c\u5f88\u53ef\u80fd\u8fdc\u8d85\u9884\u671f\uff01\\n\\n## \u53c2\u8003\u6587\u732e\\n\\n[^1]: S. Kim, S. Gella, D. Jin, A. Papangelis, B. Hedayatnia, and Y. Liu, \u201cTask-oriented Conversational Modeling with Subjective Knowledge,\u201d p. 4."},{"id":"/2022/11/12/bert-family","metadata":{"permalink":"/blog/2022/11/12/bert-family","editUrl":"https://github.com/kcxain/Kcx_Learning/tree/master/blog/2022/11-12-bert-family.md","source":"@site/blog/2022/11-12-bert-family.md","title":"BERT \u5bb6\u65cf\u5927\u5168\u89e3\u2014\u2014RoBERTa, DeBERTa","description":"\u672c\u6587\u5c06\u5bf9 BERT \u53ca\u5176\u53d8\u79cd\u6a21\u578b\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd\u548c\u5206\u6790\uff0c\u5305\u62ec RoBERTa\u3001DeBERTa\u3001BART \u7b49\uff0c\u5e0c\u671b\u80fd\u591f\u4e3a\u8bfb\u8005\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u7684\u6982\u89c8\u548c\u53c2\u8003\u3002","date":"2022-11-12T00:00:00.000Z","formattedDate":"2022\u5e7411\u670812\u65e5","tags":[{"label":"NLP","permalink":"/blog/tags/nlp"},{"label":"deep learning","permalink":"/blog/tags/deep-learning"}],"readingTime":1.985,"hasTruncateMarker":true,"authors":[{"name":"Kcxain","url":"https://github.com/kcxain","email":"kcxain@gmail.com","imageURL":"https://github.com/kcxain.png","key":"kcxain"}],"frontMatter":{"authors":"kcxain","tags":["NLP","deep learning"]},"prevItem":{"title":"DSTC11-Track5 \u7ade\u8d5b\u603b\u7ed3","permalink":"/blog/2023/04/10/dstc"},"nextItem":{"title":"BERT \u539f\u7406\u4e0e\u4ee3\u7801\u89e3\u6790","permalink":"/blog/2022/08/04/bert-code"}},"content":"![](./assets/1686580600888.jpeg)\\n\\n\x3c!--truncate--\x3e\\n\\n\u672c\u6587\u5c06\u5bf9 BERT \u53ca\u5176\u53d8\u79cd\u6a21\u578b\u8fdb\u884c\u5168\u9762\u7684\u4ecb\u7ecd\u548c\u5206\u6790\uff0c\u5305\u62ec RoBERTa\u3001DeBERTa\u3001BART \u7b49\uff0c\u5e0c\u671b\u80fd\u591f\u4e3a\u8bfb\u8005\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u7684\u6982\u89c8\u548c\u53c2\u8003\u3002\\n\\n## BERT\\n\\n\u89c1\uff1a[BERT \u539f\u7406\u4e0e\u4ee3\u7801\u89e3\u6790](/blog/2022/11/04/bert-code)\\n\\n## RoBERTa\\n\\n\u8bba\u6587\uff1a[RoBERTa: A Robustly Optimized BERT Pretraining Approach (arxiv.org)](https://arxiv.org/abs/1907.11692)\\n\\n\u6539\u8fdb\u70b9\uff1a\\n\\n- \u4fee\u6539\u4e86\u8d85\u53c2\u6570\uff1a\u5c06 adam \u7684 $\\\\beta_2$ \u53c2\u6570\u4ece 0.999 \u6539\u4e3a 0.98\\n- \u52a0\u5165\u4e86\u6df7\u5408\u7cbe\u5ea6\\n- \u52a0\u5927batch size\uff1a\u4ece BERT \u7684 256 \u6539\u4e3a 2K \u751a\u81f3 8K\uff0c\u8bad\u7ec3\u6b65\u6570\u4ece 1M \u964d\u5230 500K\\n- \u5728\u66f4\u957f\u7684\u5e8f\u5217\u4e0a\u8bad\u7ec3\uff0c\u4fee\u6539\u8f93\u5165\u683c\u5f0f\uff1aFULL-SENTENCES + \u79fb\u9664 NSP \u4efb\u52a1\\n- \u52a8\u6001\u63a9\u7801\u673a\u5236\\n\\n### \u52a8\u6001\u63a9\u7801\\n\\nBERT \u5728\u9884\u8bad\u7ec3\u65f6\u5bf9\u6570\u636e\u8fdb\u884c mask\uff0c\u4e00\u65e6\u5904\u7406\u597d\u4fbf\u4e0d\u4f1a\u518d\u53d8\uff0c\u8fd9\u4fbf\u662f**\u9759\u6001\u63a9\u7801**\u3002RoBERTa \u6240\u8c13\u7684\u52a8\u6001\u63a9\u7801\u5c31\u662f\u6bcf\u6b21\u8f93\u5165\u65f6\u90fd\u968f\u673a\u8fdb\u884c mask\uff0c\u8fd9\u6837\uff0c\u5728\u5927\u91cf\u6570\u636e\u4e0d\u65ad\u8f93\u5165\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6a21\u578b\u4f1a\u9010\u6e10\u9002\u5e94\u4e0d\u540c\u7684\u63a9\u7801\u7b56\u7565\uff0c\u5b66\u4e60\u4e0d\u540c\u7684\u8bed\u8a00\u8868\u5f81\u3002\\n\\n### \u79fb\u9664NSP\u4efb\u52a1\\n\\n\u4f5c\u8005\u5bf9\u6bd4\u4e86\u56db\u79cd\u8f93\u5165\u6a21\u5f0f\uff1a\\n\\n- SEGMENT-PAIR+NSP\uff1aBERT \u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u8f93\u5165\u6709\u4e00\u5bf9\u6bb5\u843d\uff0c\u6bb5\u843d\u4e4b\u95f4\u7528 [SEP] \u5206\u5272\uff0c\u5e76\u4e14\u8ba1\u7b97 NSP \u635f\u5931\\n- SENTENCE-PAIR+NSP\uff1a\u5c06 segment \u66ff\u6362\u4e3a sentence\\n- FULL-SENTENCES\uff1a\u5982\u679c\u8f93\u5165\u7684\u6700\u5927\u957f\u5ea6\u4e3a512\uff0c\u90a3\u4e48\u5c31\u662f\u5c3d\u91cf\u9009\u62e9 512 \u957f\u5ea6\u7684\u8fde\u7eed\u53e5\u5b50\u3002\u5982\u679c\u8de8 document\u4e86\uff0c\u5c31\u5728\u4e2d\u95f4\u52a0\u4e0a\u4e00\u4e2a\u7279\u6b8a\u5206\u9694\u7b26\uff0c\u4e0d\u4f7f\u7528 NSP \u635f\u5931\\n- DOC-SENTENCES\uff1a\u548c FULL-SENTENCES \u4e00\u6837\uff0c\u53ea\u662f\u4e0d\u80fd\u8de8\u6587\u6863\\n\\n\u5b9e\u9a8c\u7ed3\u679c\uff1a\\n\\n![](./assets/image-20230613003736967.png)\\n\\n## DeBERTa\uff1a\u5177\u6709\u89e3\u7801\u589e\u5f3a\u548c\u6ce8\u610f\u529b\u89e3\u8026\u7684 BERT\\n\\n\\n\\n## \u53c2\u8003\\n\\n- [\u4e07\u5b57\u957f\u6587\u5e26\u4f60\u7eb5\u89c8 BERT \u5bb6\u65cf - \u77e5\u4e4e (zhihu.com)](https://zhuanlan.zhihu.com/p/145119424)"},{"id":"/2022/08/04/bert-code","metadata":{"permalink":"/blog/2022/08/04/bert-code","editUrl":"https://github.com/kcxain/Kcx_Learning/tree/master/blog/2022/08-04-bert-code.md","source":"@site/blog/2022/08-04-bert-code.md","title":"BERT \u539f\u7406\u4e0e\u4ee3\u7801\u89e3\u6790","description":"\u8bba\u6587\uff1aBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","date":"2022-08-04T00:00:00.000Z","formattedDate":"2022\u5e748\u67084\u65e5","tags":[{"label":"NLP","permalink":"/blog/tags/nlp"},{"label":"deep learning","permalink":"/blog/tags/deep-learning"}],"readingTime":2.315,"hasTruncateMarker":true,"authors":[{"name":"Kcxain","url":"https://github.com/kcxain","email":"kcxain@gmail.com","imageURL":"https://github.com/kcxain.png","key":"kcxain"}],"frontMatter":{"authors":"kcxain","tags":["NLP","deep learning"]},"prevItem":{"title":"BERT \u5bb6\u65cf\u5927\u5168\u89e3\u2014\u2014RoBERTa, DeBERTa","permalink":"/blog/2022/11/12/bert-family"}},"content":"\u8bba\u6587\uff1a[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\\n\\n\u6a21\u578b\u7531\u8f93\u5165\u5c42\uff08Embedding\uff09\uff0c\u7f16\u7801\u5c42\uff08Transformer-Encoder\uff09\u548c\u8f93\u51fa\u5c42\u4e09\u90e8\u5206\u7ec4\u6210\u3002\\n\\n## \u6a21\u578b\u7ed3\u6784\\n\\n### \u8f93\u5165\u5c42\\n\\n![](./assets/image-20230612231726961.png)\\n\\n- Token Embedding\uff1a\u8bcd\u5411\u91cf\uff0c\u7b2c\u4e00\u4e2a Token \u662f [CLS]\uff0c\u4f5c\u4e3a\u6574\u4e2a\u53e5\u5b50\u7684\u8868\u5f81\uff0c\u53ef\u4ee5\u7528\u6765\u505a\u5206\u7c7b\u4efb\u52a1\\n- Segment Embedding\uff1a\u7528\u6765\u533a\u5206\u4e24\u79cd\u53e5\u5b50\\n- Position Embedding\uff1a\u4e0e transformer \u7684 position encoding \u4e0d\u540c\uff0c\u8fd9\u91cc\u7684 Position Embedding \u662f\u81ea\u5df1\u5b66\u4e60\u7684\\n\\n\x3c!--truncate--\x3e\\n\\n### \u7f16\u7801\u5c42\\n\\nBERT \u4ec5\u4ec5\u4f7f\u7528 transformer \u7684 encoder\uff0c\\n\\n![](./assets/image-20230612232548339.png)\\n\\n## \u9884\u8bad\u7ec3\\n\\n### Task 1#: Masked LM\\n\\n\u9996\u5148\uff0c\u4f7f\u7528 [MASK] \u968f\u673a mask \u6389 15% \u7684 token\uff0c\u4f46\u662f\u5728\u662f\u9884\u6d4b\u4e2d\uff0c\u6a21\u578b\u65f6\u9047\u4e0d\u5230 [MASK] \u7684\uff0c\u6240\u4ee5\u4e3a\u4e86\u907f\u514d\u5f71\u54cd\u6a21\u578b\uff0c\u5f53\u9009\u5b9a\u4e00\u4e2a\u5f85 mask \u7684\u8bcd\u65f6\uff0c\u4f7f\u7528\u5982\u4e0b\u7b56\u7565\uff1a\\n\\n1. 80% \u7684\u6982\u7387\u5c06\u5176\u66ff\u6362\u4e3a[MASK]\\n2. 10% \u7684\u6982\u7387\u5c06\u5176\u968f\u673a\u66ff\u6362\u4e3a\u5176\u5b83 token\\n3. 10% \u7684\u6982\u7387\u4e0d\u6539\u53d8\u5b83\\n\\n\u505a MLM \u8bad\u7ec3\u65f6\uff0c\u5c31\u662f\u5c06 mask \u6389\u7684 token \u7684\u6700\u540e\u4e00\u5c42\u9690\u85cf\u5c42\u5411\u91cf\u8f93\u5165\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u7136\u540e\u5728\u6574\u4e2a\u8bcd\u8868\u4e0a\u505a softmax\uff0c\u5373\u5f97\u5230\u4e86\u6bcf\u4e2a\u8bcd\u7684\u6982\u7387\uff0c\u635f\u5931\u51fd\u6570\u7528\u4ea4\u53c9\u71b5\u3002\\n\\n\u6838\u5fc3\u4ee3\u7801\u5982\u4e0b\uff1a\\n\\n```python\\nclass BertLMPredictionHead(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.transform = BertPredictionHeadTransform(config)\\n\\n        # The output weights are the same as the input embeddings, but there is\\n        # an output-only bias for each token.\\n        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\\n\\n        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\\n\\n        # Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`\\n        self.decoder.bias = self.bias\\n\\n    def forward(self, hidden_states):\\n        hidden_states = self.transform(hidden_states)\\n        hidden_states = self.decoder(hidden_states)\\n        return hidden_states\\n```\\n\\n### Task 2#: Next Sentence Prediction\\n\\n\u56e0\u4e3a\u6d89\u53ca\u5230 QA \u548c NLI \u4e4b\u7c7b\u7684\u4efb\u52a1\uff0c\u589e\u52a0\u4e86\u7b2c\u4e8c\u4e2a\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u8054\u7cfb\u3002\u8bad\u7ec3\u7684\u8f93\u5165\u662f\u53e5\u5b50 A \u548c B\uff0cB \u6709\u4e00\u534a\u7684\u51e0\u7387\u662fA\u7684\u4e0b\u4e00\u53e5\uff0c\u8f93\u5165\u8fd9\u4e24\u4e2a\u53e5\u5b50\uff0c\u6a21\u578b\u9884\u6d4b B \u662f\u4e0d\u662f A \u7684\u4e0b\u4e00\u53e5\u3002\\n\\n\u8fd9\u5c31\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u4f7f\u7528 [CLS] \u8f93\u5165\u5230\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u7136\u540e\u505a softmax \u5373\u53ef\u3002\\n\\n## \u5fae\u8c03\\n\\n![](./assets/image-20230612235434891.png)"}]}')}}]);