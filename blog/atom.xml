<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://deconx.cn/blog</id>
    <title>Kcxain's Blog Blog</title>
    <updated>2023-05-18T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://deconx.cn/blog"/>
    <subtitle>Kcxain's Blog Blog</subtitle>
    <icon>https://deconx.cn/img/favicon.svg</icon>
    <entry>
        <title type="html"><![CDATA[【代码解读】Bert句子表征能力的改进：Condenser]]></title>
        <id>https://deconx.cn/blog/2023/05/18/condenser</id>
        <link href="https://deconx.cn/blog/2023/05/18/condenser"/>
        <updated>2023-05-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Paper a Pre-training Architecture for Dense Retrieval]]></summary>
        <content type="html"><![CDATA[<blockquote><p>Paper: <a href="https://arxiv.org/abs/2104.08253" target="_blank" rel="noopener noreferrer">Condenser: a Pre-training Architecture for Dense Retrieval</a></p><p>Code: <a href="https://github.com/luyug/Condenser" target="_blank" rel="noopener noreferrer">https://github.com/luyug/Condenser</a></p><p>Publication: EMNLP 2021</p></blockquote><p>最近在忙的项目需要一个好的方法来表征句子，于是就读到了这篇论文。这篇论文的 idea 和代码都不复杂，基本上就是对 Bert 的一个简单改造。我写本文的目的是记录学习一下它改造 bert 的代码技巧。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="一模型动机">一、模型动机<a href="#一模型动机" class="hash-link" aria-label="一、模型动机的直接链接" title="一、模型动机的直接链接">​</a></h2><p>Condenser 的动机来源于一个已发现的现象：一个预训练好的 Bert 中，中间层的 CLS 与句子中的其他 token 的 attention 系数很低，直到最后一层 CLS 才与所有的 token 有比较大的 attention系数。所以，是否可以让最后一层的 CLS 向量与中间层的其它 token 的向量做 self-attention 学习呢？</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="二模型结构">二、模型结构<a href="#二模型结构" class="hash-link" aria-label="二、模型结构的直接链接" title="二、模型结构的直接链接">​</a></h2><p>基于这样的动机，模型如下：</p><p><img loading="lazy" src="/assets/images/image-20230518103007659-6d4ad1fc9cd668bdd2bfae78f9eb2ca6.png" width="978" height="761" class="img_ev3q"></p><p>将 12 层 BertLayer 分为 Late 和 Early，各 6 层。用第 12 层的 CLS 位置向量与第 6 层除 CLS 位置的其他隐藏向量拼接成原长度的输出向量，最后接一个 2 层 BertLayer 训练。</p><p>12 层 BertLayer 的权重就从已经预训练好的 Bert 中加载。而由于最上面的两层 BertLayer 是自己添加的，其权重是随机初始化的。为了防止这两层的随机权重在反向传播时对整个模型的权重有破坏。所以在设计损失函数时，把最原始的 Bert 的 MLM 损失也要加上。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="三代码解读">三、代码解读<a href="#三代码解读" class="hash-link" aria-label="三、代码解读的直接链接" title="三、代码解读的直接链接">​</a></h2><p>下面介绍我学到的一些代码技巧。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-如何初始化的自定义-bertlayer">1. 如何初始化的自定义 BertLayer？<a href="#1-如何初始化的自定义-bertlayer" class="hash-link" aria-label="1. 如何初始化的自定义 BertLayer？的直接链接" title="1. 如何初始化的自定义 BertLayer？的直接链接">​</a></h3><p>首先，需要定义自己设置的 BertLayer：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">c_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ModuleList</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 论文中model_args.n_head_layers=2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">BertLayer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">bert</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">n_head_layers</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>对于这个 ModuleList 中的每个 Module，可以使用 apply 方法，进行权重初始化，这个方法需要一个接收 Module 为参数的函数</p><p>huggingface 的每个<code>PreTrainedModel</code>都有<code>init_weights</code>方法，这是说明文档：</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span><mdxadmonitiontitle><code>init_weights</code></mdxadmonitiontitle></div><div class="admonitionContent_S0QG"><p>If needed prunes and maybe initializes weights. If using a custom <code>PreTrainedModel</code>, you need to implement any initialization logic in <code>_init_weights</code>.</p></div></div><p>所以，可以直接调用 BertModel 的初始化权重方法来初始化自定义的 BertLayer：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> BertModel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">c_head</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">apply</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">_init_weights</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>我们也可以看看 BertModel 中的这个方法：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">_init_weights</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Initialize the weights"""</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Slightly different from the TF version which uses truncated_normal for initialization</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># cf https://github.com/pytorch/pytorch/pull/5617</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">normal_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">mean</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> std</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">initializer_range</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bias </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">not</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bias</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">normal_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">mean</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> std</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">initializer_range</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">padding_idx </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">not</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">padding_idx</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">LayerNorm</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bias</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fill_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Bert 中的 initializer_range=0.02，也就是用 mean=0，std=0.02 来随机初始化参数。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2如何得到特定隐藏层的输出">2.如何得到特定隐藏层的输出？<a href="#2如何得到特定隐藏层的输出" class="hash-link" aria-label="2.如何得到特定隐藏层的输出？的直接链接" title="2.如何得到特定隐藏层的输出？的直接链接">​</a></h3><p><code>MaskedLMOutput</code>有这样几个值：</p><ul><li>last_hidden_state: (batch_size, sequence_length, hidden_size)，最后一层输出的隐藏状态</li><li>pooler_output: (batch_size, hidden_size)，序列第一个 token 最后一层的隐藏状态</li><li>hidden_states: 需要指定<code>config.output_hidden_states=True</code>，这是一个元组，第一个元素为 embedding，其余元素是各层的输出，每个元素的形状为 (batch_size, sequence_length, hidden_size)</li><li>attentions: 需要 <code>config.output_attentions=True</code>，这是一个元组，元素是每一层的注意力权重</li></ul><p>所以，要得到 CLS 最后一层的输出，可以这样：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cls_hiddens </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> lm_out</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">hidden_states</span><span class="token punctuation" style="color:#393A34">[</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>得到其它位置第 6 层的输出，可以这样：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">skip_hiddens </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> lm_out</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">hidden_states</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">6</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="三todo">三、TODO<a href="#三todo" class="hash-link" aria-label="三、TODO的直接链接" title="三、TODO的直接链接">​</a></h2><p>暂且先写这些内容，以后有时间就以这个模型为例讲讲如何把自己的模型加入 transformers 库中</p>]]></content>
        <author>
            <name>Kcxain</name>
            <email>kcxain@gmail.com</email>
            <uri>https://github.com/kcxain</uri>
        </author>
        <category label="NLP" term="NLP"/>
        <category label="代码解读" term="代码解读"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[DSTC11-Track5 竞赛总结]]></title>
        <id>https://deconx.cn/blog/2023/04/10/dstc</id>
        <link href="https://deconx.cn/blog/2023/04/10/dstc"/>
        <updated>2023-04-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[昨天，DSTC 竞赛的结果出来了。排名出乎意料：一共 14 个队提交，我队按照客观指标排在第 3 名！排名如图（我队为第 7 队）]]></summary>
        <content type="html"><![CDATA[<p>昨天，DSTC 竞赛的结果出来了。排名出乎意料：一共 14 个队提交，我队按照客观指标排在第 3 名！排名如图（我队为第 7 队）</p><p><img loading="lazy" src="/assets/images/image-20230410172909573-c21f99440fe3a20d74674e597b20680e.png" width="2371" height="906" class="img_ev3q"></p><p>可以看到，虽然和前两队差距较大，但第 3 已经是一个相当不错的名次了（尤其是我负责的 Turn Detection 部分拿到了第 1 名！)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="赛题介绍">赛题介绍<a href="#赛题介绍" class="hash-link" aria-label="赛题介绍的直接链接" title="赛题介绍的直接链接">​</a></h2><p>DSTC11-Track5 的主题是 Task-oriented Conversational Modeling with Subjective Knowledge，就是利用主观知识对任务型对话进行建模。</p><p> 整个任务被划分为了 three stage：</p><ul><li>Turn Detection。判断当前的对话是否需要外部知识</li><li>Knowledge Selection。在非结构化知识文档中选出相关的知识候选</li><li>Response Generation。根据第二步的知识候选生成回复</li></ul><p>如图所示<sup id="fnref-1-5ce6c4"><a href="#fn-1-5ce6c4" class="footnote-ref">1</a></sup>：</p><p><img loading="lazy" src="/assets/images/image-20230416233037362-d780a8ed4341dd3e299b3bed1a653120.png" width="2230" height="1168" class="img_ev3q"></p><p>给定的数据集包括多轮对话，以及每轮对话的标签（是否需要外部知识，需要的知识候选)。其中非结构化知识包含两个域，每个域又有若干实体。确定当前对话相关的实体是很重要的。</p><p>第一步、第二步的评价指标均为 Precision/Recall/F-measure，生成回复的指标为 BLEU，ROUGE，METOR。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="baseline-做法">Baseline 做法<a href="#baseline-做法" class="hash-link" aria-label="Baseline 做法的直接链接" title="Baseline 做法的直接链接">​</a></h2><p>Turn Detection 阶段：二分类问题，使用 Roberta 模型，将对话上文和查询作为输入，将 Roberta 的 CLS 标签加全连接层后作为输出，损失函数用交叉熵。</p><p>Knowledge Sealetion 阶段：还是将问题看作二分类任务，对每一条知识逐一判断是否加入候选，与 Turn Detection 相同的做法，只不过输入增加了需要判断的知识条目。这种做法需要对每一条知识逐一判断，时间消耗难以承受，因此，Baseline 提出的改进是，先在对话上文中使用机械的模糊匹配来确定当前对话所关联的域，然后对这个域中的知识再逐一判断。</p><p>Response Generation 阶段：使用 Bard 模型，将对话上文，查询，知识候选输入得到回复。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="竞赛过程">竞赛过程<a href="#竞赛过程" class="hash-link" aria-label="竞赛过程的直接链接" title="竞赛过程的直接链接">​</a></h2><p>我们是从 2 月 20 日开始准备的，到 4 月 1 日提交结果差不多有一个半月的时间。前期的工作主要就是读 Baseline，读领域内论文。在这期间，对我提升很大的是读 Baseline 代码。DSTC 组织方提供的代码架构简直太好了，模块之间耦合度低，整份代码的可维护性和可扩展性非常高，读起来简直就是一种享受！（我昨天才写完的论文实验就是在这个架构上修改的）。而读领域内论文却足足使我煎熬了一个月，尤其是往届 DSTC 竞赛投稿的 Workshop 论文，提出的很多 idea 很好，但是开源的代码却没一个能跑。我花了一个月时间天天整理、调试这些代码，跑通后的效果却非常差劲，我至今不清楚是论文数据的问题还是我写的代码的问题。总之，这一个月殚精竭虑，却几乎没有任何产出。</p><p>从 3 月 20 日开始，我便放弃了使用他人论文的 idea，而是在 Baseline 上修改。主要通过以下方式提高模型能力：</p><ul><li><strong>数据</strong>方面。对数据集采用回译的方式进行数据增强</li><li><strong>模型</strong>方面。先使用数据集对模型进行预训练后再在特定任务上微调；换用不同参数大小的模型，修改不同的学习率，查看收敛后的结果</li><li><strong>模型融合</strong>。最后通过模型融合提高模型在分类任务上的准确率（这大概是 Task 1 能拿到第 1 名的主要原因）</li></ul><p>这期间，我还用了一个晚上，通过把 Baseline 的 Task 2 损失函数换为 infoNCE 的方式，将任务从二分类问题转换为排序问题。然而最后的效果却是惨不忍睹。也是从这以后，我完全放弃了在 Baseline 的模型结构上动刀。</p><p>现在想想，其实这次比赛前期的读论文、复现论文工作也并不是毫无意义的。我在这个过程中学习到了数据增强的技巧，加深了相关领域任务的理解，对后面的调参工作有很大的积极作用。当然，调参工作也有很多可以改进的地方：</p><ul><li>应首先分析、提升原始数据的质量。例如：根据标签、数据长度去除低质量数据</li><li>应搜集一切可以搜集到的相关领域数据进行模型预训练。例如，Wizard of Wikipedia 数据集也是多轮对话且标注外部知识点的数据集，完全可以拿来做预训练甚至微调</li></ul><p>我对这场竞赛的结果本来是很不看好的，因为我们最后做的基本都是调参、换模型这类工作，排名怎么会高呢？然而事实证明，这样做就是能拿到不错的排名。我个人认为原因是在 nlp 堆大预训练模型的时代，数据大小、数据质量对模型效果的影响远远超过模型结构本身。</p><p>总之，以后在参加竞赛时，先不要去想那些天马行空的 idea，不妨去做做数据增强，调调参吧，结果很可能远超预期！</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="参考文献">参考文献<a href="#参考文献" class="hash-link" aria-label="参考文献的直接链接" title="参考文献的直接链接">​</a></h2><div class="footnotes"><hr><ol><li id="fn-1-5ce6c4">S. Kim, S. Gella, D. Jin, A. Papangelis, B. Hedayatnia, and Y. Liu, “Task-oriented Conversational Modeling with Subjective Knowledge,” p. 4.<a href="#fnref-1-5ce6c4" class="footnote-backref">↩</a></li></ol></div>]]></content>
        <author>
            <name>Kcxain</name>
            <email>kcxain@gmail.com</email>
            <uri>https://github.com/kcxain</uri>
        </author>
        <category label="NLP" term="NLP"/>
    </entry>
</feed>