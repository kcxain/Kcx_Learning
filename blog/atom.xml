<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://deconx.cn/blog</id>
    <title>Kcxain's Blog Blog</title>
    <updated>2023-04-10T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://deconx.cn/blog"/>
    <subtitle>Kcxain's Blog Blog</subtitle>
    <icon>https://deconx.cn/img/favicon.svg</icon>
    <entry>
        <title type="html"><![CDATA[DSTC11-Track5 竞赛总结]]></title>
        <id>https://deconx.cn/blog/2023/04/10/dstc</id>
        <link href="https://deconx.cn/blog/2023/04/10/dstc"/>
        <updated>2023-04-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[昨天，DSTC 竞赛的结果出来了。排名出乎意料：一共 14 个队提交，我队按照客观指标排在第 3 名！排名如图（我队为第 7 队）]]></summary>
        <content type="html"><![CDATA[<p>昨天，DSTC 竞赛的结果出来了。排名出乎意料：一共 14 个队提交，我队按照客观指标排在第 3 名！排名如图（我队为第 7 队）</p><p><img loading="lazy" src="/assets/images/image-20230410172909573-c21f99440fe3a20d74674e597b20680e.png" width="2371" height="906" class="img_ev3q"></p><p>可以看到，虽然和前两队差距较大，但第 3 已经是一个相当不错的名次了（尤其是我负责的 Turn Detection 部分拿到了第 1 名！)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="赛题介绍">赛题介绍<a href="#赛题介绍" class="hash-link" aria-label="赛题介绍的直接链接" title="赛题介绍的直接链接">​</a></h2><p>DSTC11-Track5 的主题是 Task-oriented Conversational Modeling with Subjective Knowledge，就是利用主观知识对任务型对话进行建模。</p><p> 整个任务被划分为了 three stage：</p><ul><li>Turn Detection。判断当前的对话是否需要外部知识</li><li>Knowledge Selection。在非结构化知识文档中选出相关的知识候选</li><li>Response Generation。根据第二步的知识候选生成回复</li></ul><p>如图所示<sup id="fnref-1-5ce6c4"><a href="#fn-1-5ce6c4" class="footnote-ref">1</a></sup>：</p><p><img loading="lazy" src="/assets/images/image-20230416233037362-d780a8ed4341dd3e299b3bed1a653120.png" width="2230" height="1168" class="img_ev3q"></p><p>给定的数据集包括多轮对话，以及每轮对话的标签（是否需要外部知识，需要的知识候选)。其中非结构化知识包含两个域，每个域又有若干实体。确定当前对话相关的实体是很重要的。</p><p>第一步、第二步的评价指标均为 Precision/Recall/F-measure，生成回复的指标为 BLEU，ROUGE，METOR。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="baseline-做法">Baseline 做法<a href="#baseline-做法" class="hash-link" aria-label="Baseline 做法的直接链接" title="Baseline 做法的直接链接">​</a></h2><p>Turn Detection 阶段：二分类问题，使用 Roberta 模型，将对话上文和查询作为输入，将 Roberta 的 CLS 标签加全连接层后作为输出，损失函数用交叉熵。</p><p>Knowledge Sealetion 阶段：还是将问题看作二分类任务，对每一条知识逐一判断是否加入候选，与 Turn Detection 相同的做法，只不过输入增加了需要判断的知识条目。这种做法需要对每一条知识逐一判断，时间消耗难以承受，因此，Baseline 提出的改进是，先在对话上文中使用机械的模糊匹配来确定当前对话所关联的域，然后对这个域中的知识再逐一判断。</p><p>Response Generation 阶段：使用 Bard 模型，将对话上文，查询，知识候选输入得到回复。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="竞赛过程">竞赛过程<a href="#竞赛过程" class="hash-link" aria-label="竞赛过程的直接链接" title="竞赛过程的直接链接">​</a></h2><p>我们是从 2 月 20 日开始准备的，到 4 月 1 日提交结果差不多有一个半月的时间。前期的工作主要就是读 Baseline，读领域内论文。在这期间，对我提升很大的是读 Baseline 代码。DSTC 组织方提供的代码架构简直太好了，模块之间耦合度低，整份代码的可维护性和可扩展性非常高，读起来简直就是一种享受！（我昨天才写完的论文实验就是在这个架构上修改的）。而读领域内论文却足足使我煎熬了一个月，尤其是往届 DSTC 竞赛投稿的 Workshop 论文，提出的很多 idea 很好，但是开源的代码却没一个能跑。我花了一个月时间天天整理、调试这些代码，跑通后的效果却非常差劲，我至今不清楚是论文数据的问题还是我写的代码的问题。总之，这一个月殚精竭虑，却几乎没有任何产出。</p><p>从 3 月 20 日开始，我便放弃了使用他人论文的 idea，而是在 Baseline 上修改。主要通过以下方式提高模型能力：</p><ul><li><strong>数据</strong>方面。对数据集采用回译的方式进行数据增强</li><li><strong>模型</strong>方面。先使用数据集对模型进行预训练后再在特定任务上微调；换用不同参数大小的模型，修改不同的学习率，查看收敛后的结果</li><li><strong>模型融合</strong>。最后通过模型融合提高模型在分类任务上的准确率（这大概是 Task 1 能拿到第 1 名的主要原因）</li></ul><p>这期间，我还用了一个晚上，通过把 Baseline 的 Task 2 损失函数换为 infoNCE 的方式，将任务从二分类问题转换为排序问题。然而最后的效果却是惨不忍睹。也是从这以后，我完全放弃了在 Baseline 的模型结构上动刀。</p><p>现在想想，其实这次比赛前期的读论文、复现论文工作也并不是毫无意义的。我在这个过程中学习到了数据增强的技巧，加深了相关领域任务的理解，对后面的调参工作有很大的积极作用。当然，调参工作也有很多可以改进的地方：</p><ul><li>应首先分析、提升原始数据的质量。例如：根据标签、数据长度去除低质量数据</li><li>应搜集一切可以搜集到的相关领域数据进行模型预训练。例如，Wizard of Wikipedia 数据集也是多轮对话且标注外部知识点的数据集，完全可以拿来做预训练甚至微调</li></ul><p>我对这场竞赛的结果本来是很不看好的，因为我们最后做的基本都是调参、换模型这类工作，排名怎么会高呢？然而事实证明，这样做就是能拿到不错的排名。我个人认为原因是在 nlp 堆大预训练模型的时代，数据大小、数据质量对模型效果的影响远远超过模型结构本身。</p><p>总之，以后在参加竞赛时，先不要去想那些天马行空的 idea，不妨去做做数据增强，调调参吧，结果很可能远超预期！</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="参考文献">参考文献<a href="#参考文献" class="hash-link" aria-label="参考文献的直接链接" title="参考文献的直接链接">​</a></h2><div class="footnotes"><hr><ol><li id="fn-1-5ce6c4">S. Kim, S. Gella, D. Jin, A. Papangelis, B. Hedayatnia, and Y. Liu, “Task-oriented Conversational Modeling with Subjective Knowledge,” p. 4.<a href="#fnref-1-5ce6c4" class="footnote-backref">↩</a></li></ol></div>]]></content>
        <author>
            <name>Kcxain</name>
            <email>kcxain@gmail.com</email>
            <uri>https://github.com/kcxain</uri>
        </author>
        <category label="NLP竞赛" term="NLP竞赛"/>
    </entry>
</feed>