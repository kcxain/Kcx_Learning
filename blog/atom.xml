<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://deconx.cn/blog</id>
    <title>潜龙勿用 Blog</title>
    <updated>2023-04-10T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://deconx.cn/blog"/>
    <subtitle>潜龙勿用 Blog</subtitle>
    <icon>https://deconx.cn/img/favicon.svg</icon>
    <entry>
        <title type="html"><![CDATA[DSTC11 竞赛复盘]]></title>
        <id>https://deconx.cn/blog/2023/04/10/weekly-summary/</id>
        <link href="https://deconx.cn/blog/2023/04/10/weekly-summary/"/>
        <updated>2023-04-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[昨天，DSTC 竞赛的结果出来了。排名出乎意料：一共 14 个队提交，我队按照客观指标排在第 3 名！排名如图（我队为第 7 队）]]></summary>
        <content type="html"><![CDATA[<p>昨天，DSTC 竞赛的结果出来了。排名出乎意料：一共 14 个队提交，我队按照客观指标排在第 3 名！排名如图（我队为第 7 队）</p><p><img loading="lazy" alt="我们是第7队" src="/assets/images/image-20230410172909573-c21f99440fe3a20d74674e597b20680e.png" width="2371" height="906" class="img_ev3q"></p><p>可以看到，虽然和前两队差距较大，但第 3 已经是一个相当不错的名次了（尤其是我负责的 Turn Detection 部分拿到了第 1 名！）</p><p>我们是从 2 月 20 日开始准备的，到 4 月 1 日提交结果差不多有一个半月的时间。前期的工作主要就是读 Baseline，读领域内论文。在这期间，对我提升很大的是读 Baseline 代码。DSTC 组织方提供的代码架构简直太好了，模块之间耦合度低，整份代码的可维护性和可扩展性非常高，读起来简直就是一种享受！（我昨天才写完的论文实验就是在这个架构上修改的）。而读领域内论文却足足使我煎熬了一个月，尤其是往届 DSTC 竞赛投稿的 Workshop 论文，提出的很多 idea 很好，但是开源的代码却没一个能跑。我花了一个月时间天天整理、调试这些代码，跑通后的效果却非常差劲，我至今不清楚是论文数据的问题还是我写的代码的问题。总之，这一个月殚精竭虑，却几乎没有任何产出。</p><p>从 3 月 20 日开始，我便放弃了使用他人论文的 idea，而是在 Baseline 上修改。主要通过以下方式提高模型能力：</p><ul><li><strong>数据</strong>方面。对数据集采用回译的方式进行数据增强</li><li><strong>模型</strong>方面。先使用数据集对模型进行预训练后再在特定任务上微调；换用不同参数大小的模型，修改不同的学习率，查看收敛后的结果</li><li><strong>模型融合</strong>。最后通过模型融合提高模型在分类任务上的准确率（这大概是 Task 1 能拿到第 1 名的主要原因）</li></ul><p>这期间，我还用了一个晚上，通过把 Baseline 的 Task 2 损失函数换为 infoNCE 的方式，将任务从二分类问题转换为排序问题。然而最后的效果却是惨不忍睹。也是从这以后，我完全放弃了在 Baseline 的模型结构上动刀。</p><p>现在想想，其实这次比赛前期的读论文、复现论文工作也并不是毫无意义的。我在这个过程中学习到了数据增强的技巧，加深了相关领域任务的理解，对后面的调参工作有很大的积极作用。当然，调参工作也有很多可以改进的地方：</p><ul><li>应首先分析、提升原始数据的质量。例如：根据标签、数据长度去除低质量数据</li><li>应搜集一切可以搜集到的相关领域数据进行模型预训练。例如，Wizard of Wikipedia 数据集也是多轮对话且标注外部知识点的数据集，完全可以拿来做预训练甚至微调</li></ul><p>我对这场竞赛的结果本来是很不看好的，因为我们最后做的基本都是调参、换模型这类工作，排名怎么会高呢？然而事实证明，这样做就是能拿到不错的排名。我个人认为原因是在 nlp 堆大预训练模型的时代，数据大小、数据质量对模型效果的影响远远超过模型结构本身。</p><p>总之，以后在参加竞赛时，先不要去想那些天马行空的 idea，不妨去做做数据增强，调调参吧，结果很可能远超预期！</p>]]></content>
        <author>
            <name>Changxin Ke</name>
            <email>kcxain@gmail.com</email>
            <uri>https://github.com/kcxain</uri>
        </author>
        <category label="复盘" term="复盘"/>
    </entry>
</feed>