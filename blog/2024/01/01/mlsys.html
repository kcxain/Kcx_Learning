<!doctype html>
<html lang="zh-Hans" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">ML system 入坑指南 | Kcxain&#x27;s Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://kkee.top/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://kkee.top/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://kkee.top/blog/2024/01/01/mlsys"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="ML system 入坑指南 | Kcxain&#x27;s Blog"><meta data-rh="true" name="description" content="转载自：摸黑干活"><meta data-rh="true" property="og:description" content="转载自：摸黑干活"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-01-01T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="MLSys"><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://kkee.top/blog/2024/01/01/mlsys"><link data-rh="true" rel="alternate" href="https://kkee.top/blog/2024/01/01/mlsys" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://kkee.top/blog/2024/01/01/mlsys" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://WBXP35154X-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Kcxain&#39;s Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Kcxain&#39;s Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Kcxain&#39;s Blog" href="/opensearch.xml">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.ea7d144a.css">
<link rel="preload" href="/assets/js/runtime~main.31a09d36.js" as="script">
<link rel="preload" href="/assets/js/main.db8639e0.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">潜龙勿用</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs">笔记</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/blog">博客</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/blog/archive">归档</a></li><li><a class="dropdown__link" href="/blog/tags">标签</a></li></ul></div><a class="navbar__item navbar__link" href="/about-me">关于我</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">更多</a><ul class="dropdown__menu"><li><a href="https://kcxain.notion.site/47ce59bd0b5c4ad4b52e3c3e5edcbf1d?v=df363f664ffe493093f511e82d906c82" target="_blank" rel="noopener noreferrer" class="dropdown__link">读论文<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://kcxain.notion.site/Schedule-97f4f2fd23e94349892d398c7b43bcd1" target="_blank" rel="noopener noreferrer" class="dropdown__link">计划复盘<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a href="https://github.com/kcxain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">ML system 入坑指南</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-01-01T00:00:00.000Z" itemprop="datePublished">2024年1月1日</time> · <!-- -->阅读需 14 分钟</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><blockquote><p>转载自：<a href="https://fazziekey.github.io/" target="_blank" rel="noopener noreferrer">摸黑干活</a></p></blockquote><p>最近ChatGPT大火，越来越多人开始关注大模型，但对于大模型落地而言，除了先进的算法，其背后的MLsystem(机器学习系统)， 从分布式训练到高效推理的完整链路同样重要， 好的基础设施是应用爆发的基础.</p><p>作为一个入坑MLsys快两年半的练习生， 本文主要围绕自己学习的经历来构筑，会持续更新，希望能给希望入坑的新人一个指引，也给非Mlsys背景但感兴趣的其他领域的同学一些启发.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="course">Course<a href="#course" class="hash-link" aria-label="Course的直接链接" title="Course的直接链接">​</a></h2><p>首先是课程，入坑MLsys，基本的计算机背景知识比如数据结构就不多聊了，更多讲讲一些更加专业性的进阶课程，</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="operating-system">Operating System<a href="#operating-system" class="hash-link" aria-label="Operating System的直接链接" title="Operating System的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="南京大学jyy-os">南京大学JYY OS<a href="#南京大学jyy-os" class="hash-link" aria-label="南京大学JYY OS的直接链接" title="南京大学JYY OS的直接链接">​</a></h4><p>南京大学JYY老师开的操作系统课内容非常硬核， workload巨大，课程质量比肩四大</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mit-6s081">MIT 6.S081<a href="#mit-6s081" class="hash-link" aria-label="MIT 6.S081的直接链接" title="MIT 6.S081的直接链接">​</a></h4><p>MIT经典OS课，资料，lab都非常全</p><ul><li><a href="https://pdos.csail.mit.edu/6.828/2020/schedule.html" target="_blank" rel="noopener noreferrer">课程主页</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/" target="_blank" rel="noopener noreferrer">MIT 6.S081 中文 Tutorial Book</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="parallel-computing">Parallel computing<a href="#parallel-computing" class="hash-link" aria-label="Parallel computing的直接链接" title="Parallel computing的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cmu15418-parallel-computing">CMU15418 Parallel computing<a href="#cmu15418-parallel-computing" class="hash-link" aria-label="CMU15418 Parallel computing的直接链接" title="CMU15418 Parallel computing的直接链接">​</a></h4><p>并行计算非常好的入门课，内容硬核，workload巨大，涉及现代多处理器，CPU加速比如SIMD，分布式通讯协议MPI，GPU加速Cuda编程，异构计算，同步，Cache</p><ul><li><a href="http://15418.courses.cs.cmu.edu/spring2016/" target="_blank" rel="noopener noreferrer">课程主页</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ucb-cs267-applications-of-parallel-computers">UCB cs267 Applications of Parallel Computers<a href="#ucb-cs267-applications-of-parallel-computers" class="hash-link" aria-label="UCB cs267 Applications of Parallel Computers的直接链接" title="UCB cs267 Applications of Parallel Computers的直接链接">​</a></h4><p>HPC祖师爷 Jim Demmel 22 spring最新版本，</p><ul><li><a href="https://sites.google.com/lbl.gov/cs267-spr2022?pli=1" target="_blank" rel="noopener noreferrer">课程主页</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="distributed-system">Distributed system<a href="#distributed-system" class="hash-link" aria-label="Distributed system的直接链接" title="Distributed system的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mit6824分布式系统">MIT6.824分布式系统<a href="#mit6824分布式系统" class="hash-link" aria-label="MIT6.824分布式系统的直接链接" title="MIT6.824分布式系统的直接链接">​</a></h4><p>这门课推荐的人也非常多了，用go实现，了解传统的分布式系统知识和历史对现代的分布式机器学习系统的学习还是有一定的帮助，不过对于做MLsys不是必须.</p><ul><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/" target="_blank" rel="noopener noreferrer">课程主页</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mlsystem">MLSystem<a href="#mlsystem" class="hash-link" aria-label="MLSystem的直接链接" title="MLSystem的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cmu-dl-system">CMU DL System<a href="#cmu-dl-system" class="hash-link" aria-label="CMU DL System的直接链接" title="CMU DL System的直接链接">​</a></h4><p>陈天奇老师的课，涉及nn库实现，自动微分，GPU加速，模型部署和部分AI编译内容，内容除了分布式训练涉及的不够，基础的MLsys还是非常全面的.</p><ul><li><a href="https://dlsyscourse.org/" target="_blank" rel="noopener noreferrer">课程主页</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mini-torch">Mini torch<a href="#mini-torch" class="hash-link" aria-label="Mini torch的直接链接" title="Mini torch的直接链接">​</a></h4><p>完全用python实现的简单torch版本，涉及自动微分，张量，GPU加速.适合新手入门</p><ul><li><a href="https://minitorch.github.io/" target="_blank" rel="noopener noreferrer">课程主页</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="机器学习系统设计和实现">机器学习系统:设计和实现<a href="#机器学习系统设计和实现" class="hash-link" aria-label="机器学习系统:设计和实现的直接链接" title="机器学习系统:设计和实现的直接链接">​</a></h4><p>华为Mindspore团队(没错，就是我打过工的Team)和一群大佬AP搞的， 计算图，编译器前后端，分布式训练都有涉及，内容比较全面，比较适合有一定基础的人阅读或者作为工具书.</p><ul><li><a href="https://openmlsys.github.io/#" target="_blank" rel="noopener noreferrer">主页</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="system-for-ai">System for AI<a href="#system-for-ai" class="hash-link" aria-label="System for AI的直接链接" title="System for AI的直接链接">​</a></h4><p>微软发起的，目前还在快速迭代更新的工具书，舍和补全基础.</p><ul><li><a href="https://github.com/microsoft/AI-System" target="_blank" rel="noopener noreferrer">主页</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ai-compilation">AI Compilation<a href="#ai-compilation" class="hash-link" aria-label="AI Compilation的直接链接" title="AI Compilation的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="machine-learning-compilation">Machine Learning Compilation<a href="#machine-learning-compilation" class="hash-link" aria-label="Machine Learning Compilation的直接链接" title="Machine Learning Compilation的直接链接">​</a></h4><p>还是陈天奇老师的课，以TVM为基础， AI编译器这样前沿的领域为数不多的课.</p><ul><li><a href="https://mlc.ai/summer22-zh/" target="_blank" rel="noopener noreferrer">课程主页</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="large-model">Large model<a href="#large-model" class="hash-link" aria-label="Large model的直接链接" title="Large model的直接链接">​</a></h3><p>对于做ML system 的同学而言，了解一些最新的算法也是非常必要的，不用过度关系一些fancy的技巧，更多关注模型架构，参数，大的范式上的变化即可.
算法的业界进展确实太快了，很难有系统的课，某些顶级大学会用讲座的形式开展，去讲GPT，PLAM这样的大模型， 看论文和官方网站，blog是更好的选择.</p><p>可以看李沐老师论文精讲去follow一些比较新且影响力巨大的工作， Muli is all you need !!!</p><ul><li><a href="https://github.com/mli/paper-reading" target="_blank" rel="noopener noreferrer">paper-reading github 主页</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="large-model-training--paper">Large model training &amp; paper<a href="#large-model-training--paper" class="hash-link" aria-label="Large model training &amp; paper的直接链接" title="Large model training &amp; paper的直接链接">​</a></h3><p>这块目前还没有比较系统的课，大规模的分布式训练开始应用也就这几年的事情，也是MLsys领域的最大热点，这里简单总结一下需要掌握的知识点和参考论文</p><ul><li>Data Parallel(数据并行)</li><li>Distributed Data Parallel(分布式数据并行)<ul><li><a href="https://arxiv.org/abs/2006.15704" target="_blank" rel="noopener noreferrer">PyTorch Distributed: Experiences on Accelerating Data Parallel Training</a></li></ul></li><li>Mix precise Training(混合精度训练)<ul><li><a href="https://arxiv.org/abs/1710.03740" target="_blank" rel="noopener noreferrer">Mix precise Training</a></li></ul></li><li>Zero Optimizer(零冗余优化器)<ul><li><a href="https://arxiv.org/abs/2104.07857" target="_blank" rel="noopener noreferrer">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li></ul></li><li>Tensor Parallel(张量并行)<ul><li>1D并行:<a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener noreferrer">Megatron-LM</a></li></ul></li><li>Pipeline Parallel(流水并行)<ul><li><a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener noreferrer">GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a></li></ul></li><li>Auto Parallel(自动并行)<ul><li><a href="https://arxiv.org/abs/2201.12023" target="_blank" rel="noopener noreferrer">Alpa:Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning</a></li></ul></li><li>Sequence Parallel(序列并行)<ul><li><a href="https://arxiv.org/abs/2105.13120" target="_blank" rel="noopener noreferrer">Sequence Parallelism: Long Sequence Training from
System Perspective</a></li></ul></li><li>Large batchsize(超大batch size)<ul><li><a href="https://arxiv.org/abs/1708.03888" target="_blank" rel="noopener noreferrer">LARS:Large Batch Training of Convolutional Networks</a></li></ul></li><li>MOE(混合专家模型)<ul><li><a href="https://arxiv.org/abs/2006.16668" target="_blank" rel="noopener noreferrer">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li></ul></li><li>Kernal Fusion(算子融合)<ul><li><a href="https://arxiv.org/abs/2205.14135" target="_blank" rel="noopener noreferrer">Flash attention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></li></ul></li><li>Optimizer Fusion(优化器融合)<ul><li><a href="https://arxiv.org/abs/2104.00237" target="_blank" rel="noopener noreferrer">OPTIMIZER FUSION: EFFICIENT TRAINING WITH BETTER LOCALITY AND PARALLELISM</a></li></ul></li><li>Activation checkpoint<ul><li><a href="https://arxiv.org/abs/1604.06174" target="_blank" rel="noopener noreferrer">Training Deep Nets with Sublinear Memory Cost</a></li></ul></li><li>Fine-tune accelerate(微调加速)<ul><li><a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">LoRA: Low-Rank Adaptation of Large Language Models</a></li></ul></li><li>Isomorphic training(异构训练)<ul><li><a href="https://arxiv.org/abs/2108.05818" target="_blank" rel="noopener noreferrer">PatrickStar: Parallel Training of Pre-trained Models via
Chunk-based Dynamic Memory Management</a></li></ul></li><li>Asynchronous Distributed Dataflow(异步数据流)<ul><li><a href="https://arxiv.org/abs/2203.12533" target="_blank" rel="noopener noreferrer">PATHWAYS: ASYNCHRONOUS DISTRIBUTED DATAFLOW FOR ML</a></li></ul></li><li>Distributed Scheduling(分布式调度)<ul><li><a href="https://arxiv.org/abs/1712.09381" target="_blank" rel="noopener noreferrer">RLlib: Abstractions for Distributed Reinforcement Learning</a></li></ul></li><li>Quant(量化)<ul><li><a href="https://arxiv.org/abs/2211.10438" target="_blank" rel="noopener noreferrer">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a></li></ul></li><li>大语言模型推理<ul><li><a href="https://github.com/FMInference/FlexGen/blob/main/docs/paper.pdf" target="_blank" rel="noopener noreferrer">FlexGen: High-throughput Generative Inference of Large Language Models with a Single GPU</a></li></ul></li></ul><blockquote><p>每个细分领域的论文还有很多，不一一列举了，对于入坑来说，抓住主线即可.</p></blockquote><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="programming-languages">Programming Languages<a href="#programming-languages" class="hash-link" aria-label="Programming Languages的直接链接" title="Programming Languages的直接链接">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="c">C++<a href="#c" class="hash-link" aria-label="C++的直接链接" title="C++的直接链接">​</a></h3><ul><li><a href="https://www.hahack.com/codes/cmake/" target="_blank" rel="noopener noreferrer">Cmake</a></li><li><a href="https://changkun.de/modern-cpp/zh-cn/01-intro/" target="_blank" rel="noopener noreferrer">现代CPP</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="python">Python<a href="#python" class="hash-link" aria-label="Python的直接链接" title="Python的直接链接">​</a></h3><p>Python基础课这个太多了，不作推荐了，做MLsys比较需要掌握用python调用C，比如Cpython，pybind，以及一些python高级特性，比如hook，装饰器</p><ul><li><a href="https://github.com/pybind/pybind11" target="_blank" rel="noopener noreferrer">pybind</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cuda">Cuda<a href="#cuda" class="hash-link" aria-label="Cuda的直接链接" title="Cuda的直接链接">​</a></h3><p>这个可以参考的也比较多，英伟达的官方手册永远是最好的参考.</p><ul><li><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/" target="_blank" rel="noopener noreferrer">Cuda programming guide</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="opencl">OpenCL<a href="#opencl" class="hash-link" aria-label="OpenCL的直接链接" title="OpenCL的直接链接">​</a></h3><p>对于非Nvidia芯片的设备，比如手机Soc，移动端推理芯片大多不支持cuda，那么用OpenCL来做异构加速就是一个更通用的方案</p><ul><li><a href="https://www.bookstack.cn/read/Heterogeneous-Computing-with-OpenCL-2.0/README.md" target="_blank" rel="noopener noreferrer">OpenCL异构计算</a></li></ul><h1>军火库</h1><p>这里会简单总结我接触或使用和直接参与开发的Mlsys的军火库，会持续更新.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="framework">Framework<a href="#framework" class="hash-link" aria-label="Framework的直接链接" title="Framework的直接链接">​</a></h2><p>对于MLsys这样前沿的领域而言，因为很多方面并没有足够的资料，经常被迫去直接学习源码，以实际的case作为学习手段也是非常好的方式.这里简单归类一下我遇到过的MLsys，大多数处于简单了解和使用，有少部分比较深入看过源码.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="inference">Inference<a href="#inference" class="hash-link" aria-label="Inference的直接链接" title="Inference的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="tensorrt">TensorRT<a href="#tensorrt" class="hash-link" aria-label="TensorRT的直接链接" title="TensorRT的直接链接">​</a></h4><p>英伟达的推理方案， 目前整体上在英伟达GPU上做的最好的推理框架，比较是自己的卡.</p><ul><li><a href="https://github.com/NVIDIA/TensorRT" target="_blank" rel="noopener noreferrer">github</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ai-template">AI Template<a href="#ai-template" class="hash-link" aria-label="AI Template的直接链接" title="AI Template的直接链接">​</a></h4><p>FaceBook刚搞的一个推理库，在很多硬件上速度性能都超过TensorRT， 还比较新的框架</p><ul><li><a href="https://github.com/facebookincubator/AITemplate" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="severing">Severing<a href="#severing" class="hash-link" aria-label="Severing的直接链接" title="Severing的直接链接">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="triton-inference-server">triton-inference-server<a href="#triton-inference-server" class="hash-link" aria-label="triton-inference-server的直接链接" title="triton-inference-server的直接链接">​</a></h4><p>英伟达的ML serving框架，比较成熟</p><ul><li><a href="https://github.com/triton-inference-server/server" target="_blank" rel="noopener noreferrer">github</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="clip-as-service">clip-as-service<a href="#clip-as-service" class="hash-link" aria-label="clip-as-service的直接链接" title="clip-as-service的直接链接">​</a></h4><p>Jina-AI做的，一家中国 start up， 在mass(model as service)上是一个非常不错的落地产品，特别喜欢</p><ul><li><a href="https://github.com/jina-ai/clip-as-service" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mobile-inference">Mobile inference<a href="#mobile-inference" class="hash-link" aria-label="Mobile inference的直接链接" title="Mobile inference的直接链接">​</a></h3><p>移动端推理是我比较深入做过的，对其底层了解的比较多</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mindsporelite">Mindsporelite<a href="#mindsporelite" class="hash-link" aria-label="Mindsporelite的直接链接" title="Mindsporelite的直接链接">​</a></h4><p>我有幸参与写过的推理引擎，对于全流程在mindspore上做的体验还是不错的.</p><ul><li><a href="https://gitee.com/mindspore/mindspore" target="_blank" rel="noopener noreferrer">gitee</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mnn">MNN<a href="#mnn" class="hash-link" aria-label="MNN的直接链接" title="MNN的直接链接">​</a></h4><p>阿里达摩院做的，我写mindsporelite的遇到问题的时候经常被mentor叫去学习一下友商的代码，CPU的一些kernel用汇编写的，这点映像非常深刻，代码质量非常高.</p><ul><li><a href="https://github.com/alibaba/MNN" target="_blank" rel="noopener noreferrer">github</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="tensorflowlite">TensorFlowlite<a href="#tensorflowlite" class="hash-link" aria-label="TensorFlowlite的直接链接" title="TensorFlowlite的直接链接">​</a></h4><p>集成在Tensorflow的移动端推引擎，国际上应该是最早做的移动端推理.没错，TFlite的大哥就是那个从谷歌跑路重回斯坦福读博的皮特·沃登，他写了TinyML这本书，对整个移动端推理都是有重要意义的.我也从这学习了不少.google的代码质量太高了，看注释都能学很多.</p><ul><li><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite" target="_blank" rel="noopener noreferrer">github</a></li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ncnn">NCNN<a href="#ncnn" class="hash-link" aria-label="NCNN的直接链接" title="NCNN的直接链接">​</a></h4><p>国内做的最早的端侧推理引擎，腾讯搞的，不得不说，很多东西还是需求驱动， 靠各种移动APP为主要产品的中国互联网公司，移动推理引擎做的都不错.</p><ul><li><a href="https://github.com/Tencent/ncnn" target="_blank" rel="noopener noreferrer">github</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="deeplearning-framework">DeepLearning Framework<a href="#deeplearning-framework" class="hash-link" aria-label="DeepLearning Framework的直接链接" title="DeepLearning Framework的直接链接">​</a></h2><p>大的深度学习的框架的介绍太多了，不一一介绍了，大同小异，做ML系统多少都会看看各种框架做的一些新特性，Torch2.0的一些东西可以关注.</p><ul><li><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">Torch</a></li><li><a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener noreferrer">TensorFlow</a></li><li><a href="https://gitee.com/mindspore/mindspore" target="_blank" rel="noopener noreferrer">Mindspore</a></li><li><a href="https://github.com/google/jax" target="_blank" rel="noopener noreferrer">Jax</a></li><li><a href="https://github.com/Oneflow-Inc/oneflow" target="_blank" rel="noopener noreferrer">oneflow</a></li><li><a href="https://github.com/PaddlePaddle/Paddle" target="_blank" rel="noopener noreferrer">paddle</a></li><li><a href="https://github.com/unifyai/ivy" target="_blank" rel="noopener noreferrer">ivy</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ai-compiler">AI compiler<a href="#ai-compiler" class="hash-link" aria-label="AI compiler的直接链接" title="AI compiler的直接链接">​</a></h2><p>编译这块我接触的不多，这两个项目可以参考</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="tvm">TVM<a href="#tvm" class="hash-link" aria-label="TVM的直接链接" title="TVM的直接链接">​</a></h3><ul><li><a href="https://github.com/apache/tvm" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="bladedisc">BladeDISC<a href="#bladedisc" class="hash-link" aria-label="BladeDISC的直接链接" title="BladeDISC的直接链接">​</a></h3><ul><li><a href="https://github.com/alibaba/BladeDISC" target="_blank" rel="noopener noreferrer">github</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="distributed-training">Distributed training<a href="#distributed-training" class="hash-link" aria-label="Distributed training的直接链接" title="Distributed training的直接链接">​</a></h2><p>对于大模型而言，分布式训练是比不缺的，除了最基本的分布式数据并行，各种混合并行策略，显存优化策略必不可缺，也因此出现了一系列的大模型训练框架.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="colossalai">ColossalAI<a href="#colossalai" class="hash-link" aria-label="ColossalAI的直接链接" title="ColossalAI的直接链接">​</a></h3><p>All in 参与的项目，刚刚star接近15k了，在torch生态下支持各种并行和显存优化策略，给自己打个广告，欢迎各位朋友star，关注</p><ul><li><a href="https://github.com/hpcaitech/ColossalAI" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="megatron-lm">Megatron-LM<a href="#megatron-lm" class="hash-link" aria-label="Megatron-LM的直接链接" title="Megatron-LM的直接链接">​</a></h3><p>NVIDIA做的模型并行库，也是最早开源的模型并行，但对缺乏分布式训练背景的人使用不太友好.</p><ul><li><a href="https://github.com/NVIDIA/Megatron-LM" target="_blank" rel="noopener noreferrer">Github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="deepspeed">Deepspeed<a href="#deepspeed" class="hash-link" aria-label="Deepspeed的直接链接" title="Deepspeed的直接链接">​</a></h3><p>微软的大模型训练框架，核心技术是Zero infinity相关的一系列paper，使用Megatron-LM作为张量并行的支持</p><ul><li><a href="https://github.com/microsoft/DeepSpeed-MII" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="huggingface-accelerate">huggingface accelerate<a href="#huggingface-accelerate" class="hash-link" aria-label="huggingface accelerate的直接链接" title="huggingface accelerate的直接链接">​</a></h3><p>huggingface的加速器，对各种不同硬件做了兼容，在huggingface生态下非常好用，在分布式上做了比较多的封装，可以直接调用Deepspeed.</p><ul><li><a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="bagua">Bagua<a href="#bagua" class="hash-link" aria-label="Bagua的直接链接" title="Bagua的直接链接">​</a></h3><p>Bagua在多机通讯上做了非常多的工作，对allreduce等分布式通讯做了不少优化.</p><ul><li><a href="https://github.com/BaguaSys/bagua" target="_blank" rel="noopener noreferrer">github</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="lightning">lightning<a href="#lightning" class="hash-link" aria-label="lightning的直接链接" title="lightning的直接链接">​</a></h3><p>lightning集成了各种分布式后端，可以很方便的启动各种分布式策略，lightning本身是一套更好的MLflow，设计理念是算法和工程分开，提供了大量自定义hook，对于大型AI项目而言，是个不错的选择，但是学习门槛不低，对团队人员水平要求比较高.</p><ul><li><a href="https://github.com/Lightning-AI/lightning" target="_blank" rel="noopener noreferrer">github</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="distributed-communication">Distributed Communication<a href="#distributed-communication" class="hash-link" aria-label="Distributed Communication的直接链接" title="Distributed Communication的直接链接">​</a></h2><p>在nccl之前MPI是分布式通讯的主要方式，简单了解一下还是有必要的</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mpithe-message-passing-interface">MPI(the Message Passing Interface)<a href="#mpithe-message-passing-interface" class="hash-link" aria-label="MPI(the Message Passing Interface)的直接链接" title="MPI(the Message Passing Interface)的直接链接">​</a></h3><ul><li><a href="https://mpitutorial.com/tutorials/" target="_blank" rel="noopener noreferrer">MPI Tutorials</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="tips">Tips<a href="#tips" class="hash-link" aria-label="Tips的直接链接" title="Tips的直接链接">​</a></h2><p>最后简单给几个Tips，</p><ul><li>尽可能参与到业界的项目去，多注重落地，在实验玩一些很fancy但不落地的东西意义不大，目前MLsys业界比学界跑的快太多了，学界比较有影响力的工作往往也是何大公司合作的，比如前面提到的<a href="https://arxiv.org/abs/2201.12023" target="_blank" rel="noopener noreferrer">Alpa</a>的实验就是在Google的TPU集群和AWS上做的，一般的lab更本没有条件.</li><li>及时关注各种Blog，新的论文，这个领域每天都有新的东西出来，比如我就比较喜欢每天去twitter，一些Discord channel挖宝，总能带来一些惊喜</li><li>Mlsys是一个交叉全面的领域，除了软件和算法，懂点基本的硬件，学会做产品也很重要，更多时候易用性大于性能.</li><li>新的东西肯定是看不完的，抓住主干即可，在自己做的部分保证专注</li><li>拥抱开源社区，不管是github还是huggingface，你永远想象不出开源社区的老哥的创造力</li></ul></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>标签：</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ml-sys">MLSys</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/kcxain/Kcx_Learning/tree/master/blog/2024/01-01-mlsys.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/2024/01/26/llama"><div class="pagination-nav__sublabel">较新一篇</div><div class="pagination-nav__label">LLaMA代码解读</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/2023/06/26/scir-test"><div class="pagination-nav__sublabel">较旧一篇</div><div class="pagination-nav__label">哈工大 SCIR 实验室笔试小记</div></a></nav><div style="padding-top:50px"></div></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#course" class="table-of-contents__link toc-highlight">Course</a><ul><li><a href="#operating-system" class="table-of-contents__link toc-highlight">Operating System</a></li><li><a href="#parallel-computing" class="table-of-contents__link toc-highlight">Parallel computing</a></li><li><a href="#distributed-system" class="table-of-contents__link toc-highlight">Distributed system</a></li><li><a href="#mlsystem" class="table-of-contents__link toc-highlight">MLSystem</a></li><li><a href="#ai-compilation" class="table-of-contents__link toc-highlight">AI Compilation</a></li><li><a href="#large-model" class="table-of-contents__link toc-highlight">Large model</a></li><li><a href="#large-model-training--paper" class="table-of-contents__link toc-highlight">Large model training &amp; paper</a></li></ul></li><li><a href="#programming-languages" class="table-of-contents__link toc-highlight">Programming Languages</a><ul><li><a href="#c" class="table-of-contents__link toc-highlight">C++</a></li><li><a href="#python" class="table-of-contents__link toc-highlight">Python</a></li><li><a href="#cuda" class="table-of-contents__link toc-highlight">Cuda</a></li><li><a href="#opencl" class="table-of-contents__link toc-highlight">OpenCL</a></li></ul></li><li><a href="#framework" class="table-of-contents__link toc-highlight">Framework</a><ul><li><a href="#inference" class="table-of-contents__link toc-highlight">Inference</a></li><li><a href="#severing" class="table-of-contents__link toc-highlight">Severing</a></li><li><a href="#mobile-inference" class="table-of-contents__link toc-highlight">Mobile inference</a></li></ul></li><li><a href="#deeplearning-framework" class="table-of-contents__link toc-highlight">DeepLearning Framework</a></li><li><a href="#ai-compiler" class="table-of-contents__link toc-highlight">AI compiler</a><ul><li><a href="#tvm" class="table-of-contents__link toc-highlight">TVM</a></li><li><a href="#bladedisc" class="table-of-contents__link toc-highlight">BladeDISC</a></li></ul></li><li><a href="#distributed-training" class="table-of-contents__link toc-highlight">Distributed training</a><ul><li><a href="#colossalai" class="table-of-contents__link toc-highlight">ColossalAI</a></li><li><a href="#megatron-lm" class="table-of-contents__link toc-highlight">Megatron-LM</a></li><li><a href="#deepspeed" class="table-of-contents__link toc-highlight">Deepspeed</a></li><li><a href="#huggingface-accelerate" class="table-of-contents__link toc-highlight">huggingface accelerate</a></li><li><a href="#bagua" class="table-of-contents__link toc-highlight">Bagua</a></li><li><a href="#lightning" class="table-of-contents__link toc-highlight">lightning</a></li></ul></li><li><a href="#distributed-communication" class="table-of-contents__link toc-highlight">Distributed Communication</a><ul><li><a href="#mpithe-message-passing-interface" class="table-of-contents__link toc-highlight">MPI(the Message Passing Interface)</a></li></ul></li><li><a href="#tips" class="table-of-contents__link toc-highlight">Tips</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Kcxain. Built with Docusaurus.</div><div id="contact-me" style="display:flex;justify-content:center"><a href="mailto:kcxain@gmail.com" class="linkicon_PO4W"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="font-size:36px"><path fill="currentColor" d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4 0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4c0-26.5-21.5-48-48-48H48zM0 176V384c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V176L294.4 339.2c-22.8 17.1-54 17.1-76.8 0L0 176z"></path></svg></a><a href="https://www.zhihu.com/people/deconx" class="linkicon_PO4W"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="zhihu" class="svg-inline--fa fa-zhihu" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" style="font-size:36px"><path fill="currentColor" d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z"></path></svg></a><a href="https://twitter.com/kecxain" class="linkicon_PO4W"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="font-size:36px"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://github.com/kcxain" class="linkicon_PO4W"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github-alt" class="svg-inline--fa fa-github-alt" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512" style="font-size:36px"><path fill="currentColor" d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg></a></div></div></div></footer></div>
<script src="/assets/js/runtime~main.31a09d36.js"></script>
<script src="/assets/js/main.db8639e0.js"></script>
</body>
</html>